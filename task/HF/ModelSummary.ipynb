{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/yikuan/project/Code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.pytorch import save_model\n",
    "from common.common import create_folder, H5Recorder, load_obj, H5Recorder\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from ACM.model.utils.utils import age_vocab\n",
    "import pandas as pd\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from ACM.dataLoader.HF import HF_data\n",
    "from ACM.model.bertWhitenedGP import BertHF as BertHF_GPAbs\n",
    "from ACM.model.bertKISSGP import BertHF as BertHF_GPAdditive\n",
    "from ACM.model.behrt import BertHF as BertHF_BERT\n",
    "from ACM.model.bertDBKLEmbedding import BertHF as BertHF_BNNGP\n",
    "from ACM.model.bertBayesianEmbedding import BertHF as BertHF_BNN\n",
    "from ACM.model.bertBayesianOutput import BertHF as BertHF_BNNClassifier\n",
    "from ACM.model.bertBayesianEmbeddingOutput import BertHF as BertHF_BNNEmbClassifier\n",
    "import gpytorch\n",
    "from ACM.model.optimiser import adam\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from Utils.evaluation import ECELoss,uncertainty_divergence\n",
    "from matplotlib.pyplot import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ACM.evaluation.metrics import uncertain_cal\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from sklearn.calibration import calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model GPAbs\n",
    "class BertConfigGPAbs(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigGPAbs, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "\n",
    "class TrainConfigGPAbs(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "        \n",
    "# Model GPAdditive\n",
    "class BertConfigGPAdditive(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigGPAdditive, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "        \n",
    "class BertConfigBNN(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigBNN, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "\n",
    "class BertConfigBNNGP(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigBNNGP, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "        self.prior_rate = config.get('prior_rate')\n",
    "        \n",
    "class BertConfigBNNClassifier(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigBNNClassifier, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "        \n",
    "# Model Bert\n",
    "class BertConfigBERT(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "        \n",
    "class BertConfigEmbClassifier(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfigEmbClassifier, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "\n",
    "class TrainConfigGPAdditive(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "\n",
    "class TrainConfigBERT(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "\n",
    "class TrainConfigBNNGP(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "\n",
    "class TrainConfigBNN(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "        self.num_samples = config.get('num_samples')\n",
    "\n",
    "class TrainConfigBNNClassifier(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "        self.num_samples = config.get('num_samples')\n",
    "\n",
    "class TrainConfigEmbClassifier(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "        self.num_samples = config.get('num_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    'vocab':'/home/shared/yikuan/HF/Data/PureICD/Full_vocab',\n",
    "    'train': '/home/shared/01_data/03_cuts/01_model_improvement/separate_med_diag/trainV1BertDM.parquet',\n",
    "    'test': '/home/shared/01_data/03_cuts/01_model_improvement/separate_med_diag/testV1BertDM.parquet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 256,\n",
    "    'max_age': 110,\n",
    "    'month': 1,\n",
    "    'age_symbol': None,\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertVocab = load_obj(file_config['vocab'])\n",
    "ageVocab, idx2age = age_vocab(max_age=global_params['max_age'], mon=global_params['month'], symbol=global_params['age_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_parquet(file_config['train']).reset_index(drop=True)\n",
    "testData = pd.read_parquet(file_config['test']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params_GPAbs = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 0\n",
    "}\n",
    "\n",
    "train_params_GPAdditive = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3\n",
    "}\n",
    "\n",
    "train_params_BERT = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3\n",
    "}\n",
    "\n",
    "train_params_BNNGP = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3\n",
    "}\n",
    "\n",
    "train_params_BNN = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3,\n",
    "    'num_samples': 10\n",
    "}\n",
    "\n",
    "train_params_BNNClassifier = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3,\n",
    "    'num_samples': 10\n",
    "}\n",
    "\n",
    "train_params_EmbClassifier = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3,\n",
    "    'num_samples': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainConfig_GPAbs = TrainConfigGPAbs(train_params_GPAbs)\n",
    "trainConfig_GPAdditive = TrainConfigGPAdditive(train_params_GPAdditive)\n",
    "trainConfig_BERT = TrainConfigBERT(train_params_BERT)\n",
    "trainConfig_BNN = TrainConfigBNN(train_params_BNN)\n",
    "trainConfig_BNNGP = TrainConfigBNNGP(train_params_BNNGP)\n",
    "trainConfig_BNNClassifier = TrainConfigBNNGP(train_params_BNNClassifier)\n",
    "trainConfig_EmbClassifier = TrainConfigEmbClassifier(train_params_EmbClassifier)\n",
    "\n",
    "data_set = HF_data(trainConfig_GPAbs, trainData, testData, BertVocab['token2idx'], ageVocab, code='code', age='age')\n",
    "\n",
    "trainData = data_set.get_weighted_sample_train(4)\n",
    "testData = data_set.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_GPAbs = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "model_param_GPAdditive = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "model_param_BERT = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "model_param_BNNGP = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38,\n",
    "    'prior_rate': 0.347\n",
    "}\n",
    "\n",
    "model_param_BNN = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "model_param_BNNClassifier = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "model_param_EmbClassifier = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}\n",
    "\n",
    "feature_dict = {\n",
    "    'word': True,\n",
    "    'age': False,\n",
    "    'seg': False,\n",
    "    'norm': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfigGPAbs = BertConfigGPAbs(model_param_GPAbs)\n",
    "modelConfigGPAdditive = BertConfigGPAdditive(model_param_GPAdditive)\n",
    "modelConfigBERT = BertConfigGPAdditive(model_param_BERT)\n",
    "modelConfigBNN = BertConfigBNN(model_param_BNN)\n",
    "modelConfigBNNGP = BertConfigBNNGP(model_param_BNNGP)\n",
    "modelConfigBNNClassifier = BertConfigBNNClassifier(model_param_BNNClassifier)\n",
    "modelConfigEmbClassifier = BertConfigEmbClassifier(model_param_EmbClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model GPAbs\n",
    "cuda_gpAbs = 'cuda:1'\n",
    "model_GPAbs = BertHF_GPAbs(modelConfigGPAbs, n_dim=20,grid_size=40, ard_num_dims=20)\n",
    "likelihoodAbs = gpytorch.likelihoods.BernoulliLikelihood().to(cuda_gpAbs)\n",
    "mllAbs = gpytorch.mlls.VariationalELBO(likelihoodAbs, model_GPAbs.gp_layer, num_data=len(trainData.dataset))\n",
    "\n",
    "# Model GPAdditive\n",
    "cuda_gpAdditive = 'cuda:1'\n",
    "model_GPAdditive = BertHF_GPAdditive(modelConfigGPAdditive, n_dim=24,grid_size=40, ard_num_dims=24)\n",
    "likelihoodAdditive = gpytorch.likelihoods.BernoulliLikelihood().to(cuda_gpAdditive)\n",
    "mllAdditive = gpytorch.mlls.VariationalELBO(likelihoodAdditive, model_GPAdditive.gp_layer, num_data=len(trainData.dataset))\n",
    "\n",
    "# Model BERT\n",
    "cuda_bert = 'cuda:1'\n",
    "model_BERT = BertHF_BERT(modelConfigBERT, num_labels=modelConfigBERT.num_labels, n_dim=150)\n",
    "\n",
    "# BNNGP\n",
    "# cuda_bnngp_0 = 'cuda:0'\n",
    "# cuda_bnngp_1 = 'cuda:1'\n",
    "# model_BNNGP = BertHF_BNNGP(modelConfigBNNGP, n_dim=24,grid_size=40, ard_num_dims=24, feature_dict=feature_dict)\n",
    "# likelihoodBNNGP = gpytorch.likelihoods.BernoulliLikelihood().to(cuda_bnngp)\n",
    "# mllBNNGP = gpytorch.mlls.VariationalELBO(likelihoodBNNGP, model_BNNGP.gp_layer, num_data=len(trainData.dataset))\n",
    "cuda_bnngp_0 = 'cuda:1'\n",
    "cuda_bnngp_1 = 'cuda:1'\n",
    "model_BNNGP = BertHF_BNNGP(modelConfigBNNGP, n_dim=24,grid_size=40, ard_num_dims=24, feature_dict=feature_dict, cuda1=cuda_bnngp_0, cuda2=cuda_bnngp_1)\n",
    "likelihoodBNNGP = gpytorch.likelihoods.BernoulliLikelihood().to(cuda_bnngp_1)\n",
    "mllBNNGP = gpytorch.mlls.VariationalELBO(likelihoodBNNGP, model_BNNGP.gp_layer, num_data=len(trainData.dataset))\n",
    "\n",
    "# BNN\n",
    "cuda_bnn = 'cuda:1'\n",
    "model_BNN = BertHF_BNN(modelConfigBNN, num_labels=modelConfigBNN.num_labels, n_dim=150, feature_dict=feature_dict)\n",
    "\n",
    "# BNNClassifier\n",
    "cuda_bnnclassifier = 'cuda:1'\n",
    "model_BNNClassifier = BertHF_BNNClassifier(modelConfigBNNClassifier, num_labels=modelConfigBNNClassifier.num_labels, n_dim=150)\n",
    "\n",
    "# EmbClassifier\n",
    "cuda_embclassifier = 'cuda:1'\n",
    "model_EmbClassifier = BertHF_BNNEmbClassifier(modelConfigEmbClassifier, num_labels=modelConfigEmbClassifier.num_labels, n_dim=150, feature_dict=feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model, cuda='cuda:1'):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v.to(cuda) for k, v in pretrained_dict.items()}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "model_GPAbs = load_model('/home/shared/yikuan/HF/model/PureICD/GPabs_diag_med_MLM_20_40_20_best.bin', model_GPAbs, cuda_gpAbs)\n",
    "model_GPAbs = model_GPAbs.to(cuda_gpAbs)\n",
    "\n",
    "model_GPAdditive = load_model('/home/shared/yikuan/HF/model/PureICD/GPAdditive_diag_med_MLM_test_best.bin', model_GPAdditive, cuda_gpAdditive)\n",
    "model_GPAdditive = model_GPAdditive.to(cuda_gpAdditive)\n",
    "\n",
    "model_BERT = load_model('/home/shared/yikuan/HF/model/PureICD/ModelA_diag_med_MLM_best.bin', model_BERT, cuda_bert)\n",
    "model_BERT = model_BERT.to(cuda_bert)\n",
    "\n",
    "model_BNNGP = load_model('/home/shared/yikuan/Model/BayesianGPBERT/BayesianBERTGP_diag_med_5_best.bin', model_BNNGP, cuda_bnngp_0)\n",
    "model_BNNGP = model_BNNGP.to(cuda_bnngp_0)\n",
    "model_BNNGP.allocateGPU()\n",
    "\n",
    "model_BNN = load_model('/home/shared/yikuan/Model/BayesianGPBERT/BayesianBERT_diag_med_150_posterior_best.bin', model_BNN, cuda_bnn)\n",
    "model_BNN = model_BNN.to(cuda_bnn)\n",
    "\n",
    "model_BNNClassifier = load_model('/home/shared/yikuan/HF/model/PureICD/BNN_1_diag_med_MLM_best.bin', model_BNNClassifier, cuda_bnnclassifier)\n",
    "model_BNNClassifier = model_BNNClassifier.to(cuda_bnnclassifier)\n",
    "\n",
    "model_EmbClassifier = load_model('/home/shared/yikuan/Model/BayesianGPBERT/BayesianBERTClassifier_diag_med_150_posterior_best.bin', model_EmbClassifier, cuda_embclassifier)\n",
    "model_EmbClassifier = model_EmbClassifier.to(cuda_embclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def precision(logits, label):\n",
    "#     sig = nn.Sigmoid()\n",
    "#     output=sig(logits)\n",
    "#     label, output=label.cpu(), output.detach().cpu()\n",
    "#     tempprc= average_precision_score(label.numpy(),output.numpy())\n",
    "#     return tempprc, output, label\n",
    "\n",
    "def precision_GP(logits, label):\n",
    "#     sig = nn.Sigmoid()\n",
    "#     output=sig(logits)\n",
    "    tempprc= average_precision_score(label.numpy(),logits.numpy())\n",
    "    return tempprc, logits,label\n",
    "\n",
    "def precision_BERT(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    tempprc= average_precision_score(label.numpy(),output.numpy())\n",
    "    return tempprc, output, label\n",
    "\n",
    "def roc_score_GP(logits, label):\n",
    "    score= roc_auc_score(label.numpy(),logits.numpy())\n",
    "    return score, logits,label\n",
    "\n",
    "def roc_score_BERT(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    score= roc_auc_score(label.numpy(),output.numpy())\n",
    "    return score, output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_GP(testload, model, likelihood, cuda, n_sample=10):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    variance_list = []\n",
    "    predictive_list = []\n",
    "    epis_list = []\n",
    "    alea_list = []\n",
    "    age_list = []\n",
    "    patid_list = []\n",
    "    \n",
    "    loss_temp = 0\n",
    "\n",
    "#     model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, patid, last_age = batch\n",
    "\n",
    "            age_ids = age_ids.to(cuda)\n",
    "            input_ids = input_ids.to(cuda)\n",
    "            posi_ids = posi_ids.to(cuda)\n",
    "            segment_ids = segment_ids.to(cuda)\n",
    "            attMask = attMask.to(cuda)\n",
    "            targets = targets.view(-1).to(cuda)\n",
    "            last_age = last_age.view(-1)\n",
    "            \n",
    "            output_list = []\n",
    "            for _ in range(n_sample):\n",
    "                output = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)\n",
    "                output_list.append(output.sample())\n",
    "                \n",
    "            logits = torch.sigmoid(torch.stack(output_list, dim=1)).cpu()\n",
    "#             alea, epis, predictive, variance = uncertain_cal(torch.sigmoid(torch.stack(output_list, dim=1)), dim=1)\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "#             alea_list.append(alea.cpu())\n",
    "#             epis_list.append(epis.cpu())\n",
    "#             variance_list.append(variance.cpu())\n",
    "#             predictive_list.append(predictive.cpu())\n",
    "            \n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "#             variance_list.append(variance)\n",
    "            patid_list.append(patid.view(-1))\n",
    "            age_list.append(last_age)\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print('GP: {}'.format(step))\n",
    "\n",
    "        y_label = torch.cat(y_label, dim=0).view(-1)\n",
    "        y = torch.cat(y, dim=0)\n",
    "#         variance_list = torch.cat(variance_list, dim=0).view(-1)\n",
    "        patid_list = torch.cat(patid_list, dim=0).view(-1)\n",
    "        age_list = torch.cat(age_list, dim=0).view(-1)\n",
    "#         alea_list = torch.cat(alea_list, dim=0).view(-1)\n",
    "#         epis_list = torch.cat(epis_list,dim=0).view(-1)\n",
    "#         predictive_list = torch.cat(predictive_list, dim=0).view(-1)\n",
    "\n",
    "#         tempprc, output, label = precision_GP(y.view(-1), y_label.view(-1))\n",
    "#         score, _, _ = roc_score_GP(y.view(-1), y_label.view(-1))\n",
    "#         return tempprc, score, y, y_label, variance_list, patid_list, age_list, epis_list, alea_list, predictive_list\n",
    "        return y_label, y, patid_list, age_list\n",
    "\n",
    "def evaluation_BNNGP(testload, model, likelihood, cuda1, cuda2, n_sample=10):\n",
    "#     model.eval()\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    y = []\n",
    "    y_label = []\n",
    "    variance_list = []\n",
    "    epis_list = []\n",
    "    alea_list = []\n",
    "    age_list = []\n",
    "    patid_list = []\n",
    "    predictive_list = []\n",
    "    \n",
    "    loss_temp = 0\n",
    "\n",
    "#     model.eval()\n",
    "#     likelihood.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, patid, last_age = batch\n",
    "\n",
    "            age_ids = age_ids.to(cuda1)\n",
    "            input_ids = input_ids.to(cuda1)\n",
    "            posi_ids = posi_ids.to(cuda1)\n",
    "            segment_ids = segment_ids.to(cuda1)\n",
    "            attMask = attMask.to(cuda1)\n",
    "            targets = targets.view(-1).to(cuda1)\n",
    "            last_age = last_age.view(-1)\n",
    "#             output = likelihood(\n",
    "#                 model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)[0])\n",
    "            output_list = []\n",
    "            for _ in range(n_sample):\n",
    "                output, kl = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)\n",
    "                output_list.append(output.sample())\n",
    "                \n",
    "            logits = torch.sigmoid(torch.stack(output_list, dim=1)).cpu()\n",
    "#             alea, epis, predictive, variance = uncertain_cal(torch.sigmoid(torch.stack(output_list, dim=1)), dim=1)\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "#             alea_list.append(alea.cpu())\n",
    "#             epis_list.append(epis.cpu())\n",
    "#             variance_list.append(variance.cpu())\n",
    "#             predictive_list.append(predictive.cpu())\n",
    "\n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "#             variance_list.append(variance)\n",
    "            patid_list.append(patid.view(-1))\n",
    "            age_list.append(last_age)\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print('BNNGP: {}'.format(step))    \n",
    "        \n",
    "        y_label = torch.cat(y_label, dim=0).view(-1)\n",
    "        y = torch.cat(y, dim=0)\n",
    "#         variance_list = torch.cat(variance_list, dim=0).view(-1)\n",
    "        patid_list = torch.cat(patid_list, dim=0).view(-1)\n",
    "        age_list = torch.cat(age_list, dim=0).view(-1)\n",
    "#         alea_list = torch.cat(alea_list, dim=0).view(-1)\n",
    "#         epis_list = torch.cat(epis_list,dim=0).view(-1)\n",
    "#         predictive_list = torch.cat(predictive_list, dim=0).view(-1)\n",
    "\n",
    "#         tempprc, output, label = precision_GP(y.view(-1), y_label.view(-1))\n",
    "#         score, _, _ = roc_score_GP(y.view(-1), y_label.view(-1))\n",
    "#         return tempprc, score, y, y_label, variance_list, patid_list, age_list, epis_list, alea_list, predictive_list\n",
    "        return y_label, y, patid_list, age_list\n",
    "        \n",
    "def evaluation_BNN(testload, model, cuda, n_sample=10):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    variance_list = []\n",
    "    epis_list = []\n",
    "    alea_list = []\n",
    "    age_list = []\n",
    "    patid_list = []\n",
    "    predictive_list = []\n",
    "    \n",
    "    loss_temp = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, patid, last_age = batch\n",
    "\n",
    "            age_ids = age_ids.to(cuda)\n",
    "            input_ids = input_ids.to(cuda)\n",
    "            posi_ids = posi_ids.to(cuda)\n",
    "            segment_ids = segment_ids.to(cuda)\n",
    "            attMask = attMask.to(cuda)\n",
    "            targets = targets.view(-1).to(cuda)\n",
    "            last_age = last_age.view(-1)\n",
    "            \n",
    "            logits_prob = []\n",
    "            for i in range(n_sample):\n",
    "                logits =model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=None)\n",
    "                logits_prob.append(logits)\n",
    "            \n",
    "            logits = torch.sigmoid(torch.stack(logits_prob, dim=1)).cpu()\n",
    "#             alea, epis, predictive,variance = uncertain_cal(torch.sigmoid(torch.stack(logits_prob, dim=1)), dim=1)\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "#             alea_list.append(alea.cpu())\n",
    "#             epis_list.append(epis.cpu())\n",
    "#             variance_list.append(variance.cpu())\n",
    "#             predictive_list.append(predictive.cpu())\n",
    "                \n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "#             variance_list.append(variance)\n",
    "            patid_list.append(patid.view(-1))\n",
    "            age_list.append(last_age)\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print('BNN: {}'.format(step))\n",
    "                \n",
    "        y_label = torch.cat(y_label, dim=0).view(-1)\n",
    "        y = torch.cat(y, dim=0)\n",
    "#         variance_list = torch.cat(variance_list, dim=0).view(-1)\n",
    "        patid_list = torch.cat(patid_list, dim=0).view(-1)\n",
    "        age_list = torch.cat(age_list, dim=0).view(-1)\n",
    "#         alea_list = torch.cat(alea_list, dim=0).view(-1)\n",
    "#         epis_list = torch.cat(epis_list,dim=0).view(-1)\n",
    "#         predictive_list = torch.cat(predictive_list, dim=0).view(-1)\n",
    "\n",
    "#         tempprc, output, label = precision_GP(y.view(-1), y_label.view(-1))\n",
    "#         score, _, _ = roc_score_GP(y.view(-1), y_label.view(-1))\n",
    "\n",
    "#         return tempprc, score, y, y_label, variance_list, patid_list, age_list, epis_list, alea_list, predictive_list\n",
    "        return y_label, y, patid_list, age_list\n",
    "\n",
    "    \n",
    "    \n",
    "def evaluation_BERT(testload, model, cuda):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    age_list = []\n",
    "    patid_list = []\n",
    "    \n",
    "    loss_temp = 0\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, patid, last_age = batch\n",
    "\n",
    "            age_ids = age_ids.to(cuda)\n",
    "            input_ids = input_ids.to(cuda)\n",
    "            posi_ids = posi_ids.to(cuda)\n",
    "            segment_ids = segment_ids.to(cuda)\n",
    "            attMask = attMask.to(cuda)\n",
    "            targets = targets.view(-1).to(cuda)\n",
    "            last_age = last_age.view(-1)\n",
    "            patid_list.append(patid.view(-1))\n",
    "            age_list.append(last_age)\n",
    "\n",
    "            logits =model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=None)\n",
    "            targets = targets.cpu()\n",
    "\n",
    "            y_label.append(targets)\n",
    "            y.append(logits.cpu())\n",
    "            \n",
    "            if step % 500 == 0:\n",
    "                print('BERT: {}'.format(step))\n",
    "\n",
    "        y_label = torch.cat(y_label, dim=0).view(-1)\n",
    "        y = torch.cat(y, dim=0).view(-1)\n",
    "        patid_list = torch.cat(patid_list, dim=0).view(-1)\n",
    "        age_list = torch.cat(age_list, dim=0).view(-1)\n",
    "\n",
    "#         tempprc, output, label = precision_BERT(y.view(-1), y_label.view(-1))\n",
    "#         score, _, _ = roc_score_BERT(y.view(-1), y_label.view(-1))\n",
    "#         return tempprc, score, patid_list, age_list, output, y_label\n",
    "        return y_label, y, patid_list, age_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP: 0\n",
      "GP: 500\n",
      "GP: 1000\n",
      "GP: 1500\n",
      "GP: 2000\n",
      "GP: 2500\n",
      "GP: 3000\n",
      "GP: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertWhitenedGP_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_GP(testData, model_GPAbs, likelihoodAbs, cuda_gpAbs, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP: 0\n",
      "GP: 500\n",
      "GP: 1000\n",
      "GP: 1500\n",
      "GP: 2000\n",
      "GP: 2500\n",
      "GP: 3000\n",
      "GP: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertKISSGP_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_GP(testData, model_GPAdditive, likelihoodAdditive, cuda_gpAdditive, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT: 0\n",
      "BERT: 500\n",
      "BERT: 1000\n",
      "BERT: 1500\n",
      "BERT: 2000\n",
      "BERT: 2500\n",
      "BERT: 3000\n",
      "BERT: 3500\n"
     ]
    }
   ],
   "source": [
    "# recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bert.h5')\n",
    "# recorder.open(read=False)\n",
    "# label, y, patid, age = evaluation_BERT(testData, model_BERT, cuda_bert)\n",
    "# recorder.write('label', label.numpy())\n",
    "# recorder.write('prob', y.numpy())\n",
    "# recorder.write('age', age.numpy())\n",
    "# recorder.write('patid', patid.numpy())\n",
    "# recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN: 0\n",
      "BNN: 500\n",
      "BNN: 1000\n",
      "BNN: 1500\n",
      "BNN: 2000\n",
      "BNN: 2500\n",
      "BNN: 3000\n",
      "BNN: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertBayesianEmbedding_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_BNN(testData, model_BNN, cuda_bnn, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN: 0\n",
      "BNN: 500\n",
      "BNN: 1000\n",
      "BNN: 1500\n",
      "BNN: 2000\n",
      "BNN: 2500\n",
      "BNN: 3000\n",
      "BNN: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertBayesianOutput_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_BNN(testData, model_BNNClassifier, cuda_bnnclassifier, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN: 0\n",
      "BNN: 500\n",
      "BNN: 1000\n",
      "BNN: 1500\n",
      "BNN: 2000\n",
      "BNN: 2500\n",
      "BNN: 3000\n",
      "BNN: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertBayesianEmbeddingOutput_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_BNN(testData, model_EmbClassifier, cuda_embclassifier, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNNGP: 0\n",
      "BNNGP: 500\n",
      "BNNGP: 1000\n",
      "BNNGP: 1500\n",
      "BNNGP: 2000\n",
      "BNNGP: 2500\n",
      "BNNGP: 3000\n",
      "BNNGP: 3500\n"
     ]
    }
   ],
   "source": [
    "recorder = H5Recorder('/home/shared/yikuan/ACM/data/HeartFailure/bertDBKL_60.h5')\n",
    "recorder.open(read=False)\n",
    "label, y, patid, age = evaluation_BNNGP(testData, model_BNNGP, likelihoodBNNGP, cuda_bnngp_0, cuda_bnngp_1, n_sample=60)\n",
    "recorder.write('label', label.numpy())\n",
    "recorder.write('prob', y.numpy())\n",
    "recorder.write('age', age.numpy())\n",
    "recorder.write('patid', patid.numpy())\n",
    "recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('number of iteration:', i)\n",
    "# auc_GPAbs, roc_GPAbs, y_GPAbs, label_GPAbs, var_GPAbs, patid_GPAbs, age_GPAbs,epis_GPAbs, alea_GPAbs, predictive_GPAbs = evaluation_GP(testData, model_GPAbs, likelihoodAbs, cuda_gpAbs, n_sample=50)\n",
    "# print('GPAbs precision: {}, ROC: {}'.format(auc_GPAbs, roc_GPAbs))\n",
    "# auc_GPAdditive, roc_GPAdditive, y_GPAdditive, label_GPAdditive, var_GPAdditive, patid_GPAdditive, age_GPAdditive, epis_GPAdditive, alea_GPAdditive, predictive_GPAdditive = evaluation_GP(testData, model_GPAdditive, likelihoodAdditive, cuda_gpAdditive, n_sample=50)\n",
    "# print('GPAdditive precision: {}, ROC: {}'.format(auc_GPAdditive, roc_GPAdditive))\n",
    "# auc_BERT, roc_BERT, patid_BERT, age_BERT, y_Bert, label_Bert = evaluation_BERT(testData, model_BERT, cuda_bert)\n",
    "# print('BERT precision: {}, ROC: {}'.format(auc_BERT, roc_BERT))\n",
    "# auc_BNNEmb, roc_BNNEmb, y_BNNEmb, label_BNNEmb, var_BNNEmb, patid_BNNEmb, age_BNNEmb, epis_BNNEmb, alea_BNNEmb, predictive_BNNEmb = evaluation_BNN(testData, model_BNN, cuda_bnn, n_sample=50)\n",
    "# print('BNNEmb precision: {}, ROC: {}'.format(auc_BNNEmb, roc_BNNEmb))\n",
    "# auc_BNNClassifier, roc_BNNClassifier, y_BNNClassifier, label_BNNClassifier, var_BNNClassifier, patid_BNNClassifier, age_BNNClassifier, epis_BNNClassifier, alea_BNNClassifier, predictive_BNNClassifier = evaluation_BNN(testData, model_BNNClassifier, cuda_bnnclassifier, n_sample=50)\n",
    "# print('BNNClassifier precision: {}, ROC: {}'.format(auc_BNNClassifier, roc_BNNClassifier))\n",
    "# auc_EmbClassifier, roc_EmbClassifier, y_EmbClassifier, label_EmbClassifier, var_EmbClassifier, patid_EmbClassifier, age_EmbClassifier, epis_EmbClassifier, alea_EmbClassifier, predictive_EmbClassifier = evaluation_BNN(testData, model_EmbClassifier, cuda_embclassifier, n_sample=50)\n",
    "# print('EmbClassifier precision: {}, ROC: {}'.format(auc_EmbClassifier, roc_EmbClassifier))\n",
    "\n",
    "\n",
    "# df_abs =pd.DataFrame({\n",
    "#     'label':label_GPAbs.numpy(),\n",
    "#     'p_abs': y_GPAbs.numpy(),\n",
    "#     'var_abs': var_GPAbs.numpy(),\n",
    "#     'epis_abs': epis_GPAbs.numpy(),\n",
    "#     'alea_abs': alea_GPAbs.numpy(),\n",
    "#     'pred_abs': predictive_GPAbs.numpy(),\n",
    "#     'patid': patid_GPAbs.numpy(),\n",
    "#     'age': age_GPAbs.numpy()\n",
    "# })\n",
    "\n",
    "# df_additive = pd.DataFrame({\n",
    "# #     'label':label_GPAdditive.numpy(),\n",
    "#     'p_additive': y_GPAdditive.numpy(),\n",
    "#     'var_additive': var_GPAdditive.numpy(),\n",
    "#     'epis_additive': epis_GPAdditive.numpy(),\n",
    "#     'alea_additive': alea_GPAdditive.numpy(),\n",
    "#     'pred_additive': predictive_GPAdditive.numpy(),\n",
    "#     'patid': patid_GPAdditive.numpy(),\n",
    "# #     'age': age_GPAdditive.numpy()\n",
    "# })\n",
    "\n",
    "# df_bert = pd.DataFrame({\n",
    "# #     'label':label_BERT.numpy(),\n",
    "#     'p_bert': y_Bert.numpy(),\n",
    "# #     'var_additive': var_GPAdditive.numpy(),\n",
    "#     'patid': patid_BERT.numpy(),\n",
    "# #     'age': age_BERT.numpy()\n",
    "# })\n",
    "\n",
    "# df_bnnemb = pd.DataFrame({\n",
    "# #     'label':label_BERT.numpy(),\n",
    "#     'p_bnnemb': y_BNNEmb.numpy(),\n",
    "#     'var_bnnemb': var_BNNEmb.numpy(),\n",
    "#     'epis_bnnemb': epis_BNNEmb.numpy(),\n",
    "#     'alea_bnnemb': alea_BNNEmb.numpy(),\n",
    "#     'pred_bnnemb': predictive_BNNEmb.numpy(),\n",
    "#     'patid': patid_BNNEmb.numpy(),\n",
    "# #     'age': age_BERT.numpy()\n",
    "# })\n",
    "\n",
    "# df_bnnembgp = pd.DataFrame({\n",
    "# #     'label':label_BERT.numpy(),\n",
    "#     'p_bnngp': y_BNNEmbGP.numpy(),\n",
    "#     'var_bnngp': var_BNNEmbGP.numpy(),\n",
    "#     'epis_bnngp': epis_BNNEmbGP.numpy(),\n",
    "#     'alea_bnngp': alea_BNNEmbGP.numpy(),\n",
    "#     'pred_bnngp': predictive_BNNEmbGP.numpy(),\n",
    "#     'patid': patid_BNNEmbGP.numpy(),\n",
    "# #     'age': age_BERT.numpy()\n",
    "# })\n",
    "\n",
    "# df_bnnclassifier = pd.DataFrame({\n",
    "# #     'label':label_BERT.numpy(),\n",
    "#     'p_bnnclassifier': y_BNNClassifier.numpy(),\n",
    "#     'var_bnnclassifier': var_BNNClassifier.numpy(),\n",
    "#     'epis_bnnclassifier': epis_BNNClassifier.numpy(),\n",
    "#     'alea_bnnclassifier': alea_BNNClassifier.numpy(),\n",
    "#     'pred_bnnclassifier': predictive_BNNClassifier.numpy(),\n",
    "#     'patid': patid_BNNClassifier.numpy(),\n",
    "# #     'age': age_BERT.numpy()\n",
    "# })\n",
    "\n",
    "# df_embclassifier = pd.DataFrame({\n",
    "# #     'label':label_BERT.numpy(),\n",
    "#     'p_embclassifier': y_EmbClassifier.numpy(),\n",
    "#     'var_embclassifier': var_EmbClassifier.numpy(),\n",
    "#     'epis_embclassifier': epis_EmbClassifier.numpy(),\n",
    "#     'alea_embclassifier': alea_EmbClassifier.numpy(),\n",
    "#     'pred_embclassifier': predictive_EmbClassifier.numpy(),\n",
    "#     'patid': patid_EmbClassifier.numpy(),\n",
    "# #     'age': age_BERT.numpy()\n",
    "# })\n",
    "\n",
    "# df = df_abs.merge(df_additive, on='patid').merge(df_bert, on='patid').merge(df_bnnemb, on='patid').merge(df_bnnembgp, on='patid').merge(df_bnnclassifier,on='patid').merge(df_embclassifier,on='patid')\n",
    "# df.to_parquet('/home/shared/yikuan/ACM/data/Diabetes/summary.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc_BNNEmbGP, roc_BNNEmbGP, y_BNNEmbGP, label_BNNEmbGP, var_BNNEmbGP, patid_BNNEmbGP, age_BNNEmbGP,epis_BNNEmbGP, alea_BNNEmbGP, predictive_BNNEmbGP = evaluation_BNNGP(testData, model_BNNGP, likelihoodBNNGP, cuda_bnngp_0, cuda_bnngp_1, n_sample=30)\n",
    "# print('BNNGP precision: {}, ROC: {}'.format(auc_BNNEmbGP, roc_BNNEmbGP))\n",
    "\n",
    "# df_bnnembgp = pd.DataFrame({\n",
    "#     'label':label_BNNEmbGP.numpy(),\n",
    "#     'p_bnngp': y_BNNEmbGP.numpy(),\n",
    "#     'var_bnngp': var_BNNEmbGP.numpy(),\n",
    "#     'epis_bnngp': epis_BNNEmbGP.numpy(),\n",
    "#     'alea_bnngp': alea_BNNEmbGP.numpy(),\n",
    "#     'pred_bnngp': predictive_BNNEmbGP.numpy(),\n",
    "#     'patid': patid_BNNEmbGP.numpy(),\n",
    "#     'age': age_BNNEmbGP.numpy()\n",
    "# })\n",
    "\n",
    "# df_bnnembgp.to_parquet('/home/shared/yikuan/ACM/data/Diabetes/summary_DBKL.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
