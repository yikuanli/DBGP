{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/yikuan/project/Code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.pytorch import save_model\n",
    "from common.common import create_folder, load_obj\n",
    "import os\n",
    "import torch\n",
    "from ACM.model.utils.utils import age_vocab\n",
    "import pandas as pd\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from ACM.dataLoader.HF import HF_data\n",
    "from ACM.model.bertWhitenedGP import BertHF\n",
    "import gpytorch\n",
    "from ACM.model.optimiser import adam\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "# from Utils.evaluation import uncertain_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    'vocab':'/home/yikuan/project/Code/ACM/data/Full_vocab',\n",
    "    'train': '/home/shared/yikuan/ACM/data/Depression/Depression_clean_train.parquet',\n",
    "    'test': '/home/shared/yikuan/ACM/data/Depression/Depression_clean_test.parquet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 256,\n",
    "    'max_age': 110,\n",
    "    'month': 1,\n",
    "    'age_symbol': None,\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertVocab = load_obj(file_config['vocab'])\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon=global_params['month'], symbol=global_params['age_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_raw = pd.read_parquet(file_config['train']).reset_index(drop=True)\n",
    "testData_raw = pd.read_parquet(file_config['test']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 0,\n",
    "    'device': 'cuda:1',\n",
    "    'output_dir': '/home/shared/yikuan/ACM/model/Depression',\n",
    "    'output_name': 'behrtWhitenedGP.bin',\n",
    "    'best_name': 'behrtWhitenedGP_best.bin',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainConfig = TrainConfig(train_params)\n",
    "\n",
    "data_set = HF_data(trainConfig, trainData_raw, testData_raw, BertVocab['token2idx'], ageVocab, code='code', age='age')\n",
    "\n",
    "trainData = data_set.get_weighted_sample_train(4)\n",
    "testData = data_set.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfig = BertConfig(model_param)\n",
    "\n",
    "model = BertHF(modelConfig, n_dim=24,grid_size=40, ard_num_dims=1)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.BernoulliLikelihood().to(trainConfig.device)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=len(trainData.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "def load_model(path, model):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and k not in ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "model = load_model('/home/shared/yikuan/HF/MLM/PureICD_diag_med.bin', model)\n",
    "model = model.to(trainConfig.device)\n",
    "optim = adam(list(model.named_parameters()),config=optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    label, output=label.cpu(), output.detach().cpu()\n",
    "    tempprc= average_precision_score(label.numpy(),output.numpy())\n",
    "    return tempprc, output, label\n",
    "\n",
    "def precision_test(logits, label):\n",
    "#     sig = nn.Sigmoid()\n",
    "#     output=sig(logits)\n",
    "    tempprc= average_precision_score(label.numpy(),logits.numpy())\n",
    "    auc = roc_auc_score(label.numpy(),logits.numpy())\n",
    "    return tempprc, auc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, trainload, model, likelihood, optim):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    for step, batch in enumerate(trainload):\n",
    "        cnt += 1\n",
    "\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _, _ = batch\n",
    "\n",
    "        age_ids = age_ids.to(train_params['device'])\n",
    "        input_ids = input_ids.to(train_params['device'])\n",
    "        posi_ids = posi_ids.to(train_params['device'])\n",
    "        segment_ids = segment_ids.to(train_params['device'])\n",
    "        attMask = attMask.to(train_params['device'])\n",
    "        targets = targets.view(-1).to(train_params['device'])\n",
    "\n",
    "        output = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)\n",
    "        loss = -mll(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            #             prec, a, b = precision(logits, targets)\n",
    "            #             print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| precision: {}\".format(e, cnt, temp_loss / 500, prec))\n",
    "            print(\"epoch: {}\\t|step: {}\\t|Loss: {}\".format(e, step, temp_loss / 500))\n",
    "            temp_loss = 0\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    # Save a trained model\n",
    "    output_model_file = os.path.join(trainConfig.output_dir, trainConfig.output_name)\n",
    "    create_folder(trainConfig.output_dir)\n",
    "    save_model(output_model_file, model)\n",
    "\n",
    "\n",
    "def evaluation(testload, model, likelihood):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _, _ = batch\n",
    "\n",
    "            age_ids = age_ids.to(train_params['device'])\n",
    "            input_ids = input_ids.to(train_params['device'])\n",
    "            posi_ids = posi_ids.to(train_params['device'])\n",
    "            segment_ids = segment_ids.to(train_params['device'])\n",
    "            attMask = attMask.to(train_params['device'])\n",
    "            targets = targets.view(-1).to(train_params['device'])\n",
    "\n",
    "            output = likelihood(\n",
    "                model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets))\n",
    "\n",
    "            logits = output.mean.float().cpu()\n",
    "            targets = targets.cpu()\n",
    "\n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "\n",
    "        y_label = torch.cat(y_label, dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "\n",
    "        tempprc, auc, label = precision_test(y.view(-1), y_label.view(-1))\n",
    "        return tempprc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluation_GP(testload, model, likelihood, cuda, n_sample=10):\n",
    "#     model.eval()\n",
    "#     y = []\n",
    "#     y_label = []\n",
    "#     variance_list = []\n",
    "#     predictive_list = []\n",
    "#     epis_list = []\n",
    "#     alea_list = []\n",
    "#     age_list = []\n",
    "#     patid_list = []\n",
    "    \n",
    "#     loss_temp = 0\n",
    "\n",
    "# #     model.eval()\n",
    "#     likelihood.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for step, batch in enumerate(testload):\n",
    "#             age_ids, input_ids, posi_ids, segment_ids, attMask, targets, patid, last_age = batch\n",
    "\n",
    "#             age_ids = age_ids.to(cuda)\n",
    "#             input_ids = input_ids.to(cuda)\n",
    "#             posi_ids = posi_ids.to(cuda)\n",
    "#             segment_ids = segment_ids.to(cuda)\n",
    "#             attMask = attMask.to(cuda)\n",
    "#             targets = targets.view(-1).to(cuda)\n",
    "#             last_age = last_age.view(-1)\n",
    "            \n",
    "#             output_list = []\n",
    "#             for _ in range(n_sample):\n",
    "#                 output = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)\n",
    "#                 output_list.append(output.sample())\n",
    "                \n",
    "#             logits = torch.mean(torch.sigmoid(torch.stack(output_list, dim=1)),dim=1).cpu()\n",
    "#             alea, epis, predictive, variance = uncertain_cal(torch.sigmoid(torch.stack(output_list, dim=1)), dim=1)\n",
    "#             targets = targets.cpu()\n",
    "            \n",
    "#             alea_list.append(alea.cpu())\n",
    "#             epis_list.append(epis.cpu())\n",
    "#             variance_list.append(variance.cpu())\n",
    "#             predictive_list.append(predictive.cpu())\n",
    "            \n",
    "#             y_label.append(targets)\n",
    "#             y.append(logits)\n",
    "# #             variance_list.append(variance)\n",
    "#             patid_list.append(patid.view(-1))\n",
    "#             age_list.append(last_age)\n",
    "            \n",
    "# #             if step % 500 == 0:\n",
    "# #                 print('GP: {}'.format(step))\n",
    "\n",
    "#         y_label = torch.cat(y_label, dim=0).view(-1)\n",
    "#         y = torch.cat(y, dim=0).view(-1)\n",
    "#         variance_list = torch.cat(variance_list, dim=0).view(-1)\n",
    "#         patid_list = torch.cat(patid_list, dim=0).view(-1)\n",
    "#         age_list = torch.cat(age_list, dim=0).view(-1)\n",
    "#         alea_list = torch.cat(alea_list, dim=0).view(-1)\n",
    "#         epis_list = torch.cat(epis_list,dim=0).view(-1)\n",
    "#         predictive_list = torch.cat(predictive_list, dim=0).view(-1)\n",
    "\n",
    "#         tempprc, output, label = precision_GP(y.view(-1), y_label.view(-1))\n",
    "#         score, _, _ = roc_score_GP(y.view(-1), y_label.view(-1))\n",
    "#         return tempprc, score, y, y_label, variance_list, patid_list, age_list, epis_list, alea_list, predictive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t|step: 0\t|Loss: 0.0018157720565795898\n",
      "epoch: 0\t|step: 500\t|Loss: 0.7642360384464264\n",
      "epoch: 0\t|step: 1500\t|Loss: 0.6448313324451447\n",
      "epoch: 0\t|step: 2000\t|Loss: 0.5691693543195725\n",
      "epoch: 0\t|step: 2500\t|Loss: 0.4882282262444496\n",
      "epoch: 0\t|step: 3000\t|Loss: 0.468960073530674\n",
      "epoch: 0\t|step: 3500\t|Loss: 0.45135108137130736\n",
      "epoch: 0\t|step: 4000\t|Loss: 0.4521487090587616\n",
      "epoch: 0\t|step: 4500\t|Loss: 0.4526029675602913\n",
      "epoch: 0\t|step: 5000\t|Loss: 0.44211946076154707\n",
      "epoch: 0\t|step: 5500\t|Loss: 0.44521064752340317\n",
      "epoch: 0\t|step: 6000\t|Loss: 0.439584300160408\n",
      "epoch: 0\t|step: 6500\t|Loss: 0.4425163252353668\n",
      "epoch: 0\t|step: 7000\t|Loss: 0.4358431578874588\n",
      "epoch: 0\t|step: 7500\t|Loss: 0.43719022381305694\n",
      "epoch: 0\t|step: 8000\t|Loss: 0.43228470730781554\n",
      "epoch: 0\t|step: 8500\t|Loss: 0.4281401365995407\n",
      "epoch: 0\t|step: 9000\t|Loss: 0.4374574277997017\n",
      "epoch: 0\t|step: 9500\t|Loss: 0.4363287641704082\n",
      "epoch: 0\t|step: 10000\t|Loss: 0.4292000028192997\n",
      "epoch: 0\t|step: 10500\t|Loss: 0.43266487574577334\n",
      "epoch: 0\t|step: 11000\t|Loss: 0.42922262477874756\n",
      "epoch: 0\t|step: 11500\t|Loss: 0.42016387391090393\n",
      "epoch: 0\t|step: 12000\t|Loss: 0.4235042373538017\n",
      "epoch: 0\t|step: 12500\t|Loss: 0.42150003907084466\n",
      "epoch: 0\t|step: 13000\t|Loss: 0.4223738402724266\n",
      "epoch: 0\t|step: 13500\t|Loss: 0.4271565102636814\n",
      "epoch: 0\t|step: 14000\t|Loss: 0.4260805079638958\n",
      "epoch: 0\t|step: 14500\t|Loss: 0.42565303659439085\n",
      "epoch: 0\t|step: 15000\t|Loss: 0.4220126431286335\n",
      "epoch: 0\t|step: 15500\t|Loss: 0.421237799346447\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.42084371889657807, 0.7776960523033056\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 1\t|step: 0\t|Loss: 0.0007241920232772827\n",
      "epoch: 1\t|step: 500\t|Loss: 0.4197824704647064\n",
      "epoch: 1\t|step: 1000\t|Loss: 0.4268435134291649\n",
      "epoch: 1\t|step: 1500\t|Loss: 0.4227895285487175\n",
      "epoch: 1\t|step: 2000\t|Loss: 0.4318128957152367\n",
      "epoch: 1\t|step: 2500\t|Loss: 0.42580017271637915\n",
      "epoch: 1\t|step: 3000\t|Loss: 0.421225312769413\n",
      "epoch: 1\t|step: 3500\t|Loss: 0.41841603419184686\n",
      "epoch: 1\t|step: 4000\t|Loss: 0.4224296870529652\n",
      "epoch: 1\t|step: 4500\t|Loss: 0.42840412628650665\n",
      "epoch: 1\t|step: 5000\t|Loss: 0.42036489966511725\n",
      "epoch: 1\t|step: 5500\t|Loss: 0.4220467232465744\n",
      "epoch: 1\t|step: 6000\t|Loss: 0.4181920084357262\n",
      "epoch: 1\t|step: 6500\t|Loss: 0.4204168296158314\n",
      "epoch: 1\t|step: 7000\t|Loss: 0.421895710259676\n",
      "epoch: 1\t|step: 7500\t|Loss: 0.4200463891923428\n",
      "epoch: 1\t|step: 8000\t|Loss: 0.4173810606598854\n",
      "epoch: 1\t|step: 8500\t|Loss: 0.42222425431013105\n",
      "epoch: 1\t|step: 9000\t|Loss: 0.42141166776418687\n",
      "epoch: 1\t|step: 9500\t|Loss: 0.4232700826525688\n",
      "epoch: 1\t|step: 10000\t|Loss: 0.42195781859755516\n",
      "epoch: 1\t|step: 10500\t|Loss: 0.41961433354020117\n",
      "epoch: 1\t|step: 11000\t|Loss: 0.4201216889619827\n",
      "epoch: 1\t|step: 11500\t|Loss: 0.4160222043693066\n",
      "epoch: 1\t|step: 12000\t|Loss: 0.41346851471066476\n",
      "epoch: 1\t|step: 12500\t|Loss: 0.4204046927690506\n",
      "epoch: 1\t|step: 13000\t|Loss: 0.4199282386004925\n",
      "epoch: 1\t|step: 13500\t|Loss: 0.41692388099431993\n",
      "epoch: 1\t|step: 14000\t|Loss: 0.4172306859195232\n",
      "epoch: 1\t|step: 14500\t|Loss: 0.41982533982396125\n",
      "epoch: 1\t|step: 15000\t|Loss: 0.4184523830413818\n",
      "epoch: 1\t|step: 15500\t|Loss: 0.41848707631230353\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4315802306077729, 0.7811577464086984\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 2\t|step: 0\t|Loss: 0.000764718234539032\n",
      "epoch: 2\t|step: 500\t|Loss: 0.418392250597477\n",
      "epoch: 2\t|step: 1000\t|Loss: 0.4167071432173252\n",
      "epoch: 2\t|step: 1500\t|Loss: 0.4139471566975117\n",
      "epoch: 2\t|step: 2000\t|Loss: 0.41349679344892504\n",
      "epoch: 2\t|step: 2500\t|Loss: 0.4194912472963333\n",
      "epoch: 2\t|step: 3000\t|Loss: 0.41465630209445953\n",
      "epoch: 2\t|step: 3500\t|Loss: 0.411352564483881\n",
      "epoch: 2\t|step: 4000\t|Loss: 0.4149833706617355\n",
      "epoch: 2\t|step: 4500\t|Loss: 0.41614200261235235\n",
      "epoch: 2\t|step: 5000\t|Loss: 0.4177698377966881\n",
      "epoch: 2\t|step: 5500\t|Loss: 0.41642327085137365\n",
      "epoch: 2\t|step: 6000\t|Loss: 0.41613993591070175\n",
      "epoch: 2\t|step: 6500\t|Loss: 0.4118822556734085\n",
      "epoch: 2\t|step: 7000\t|Loss: 0.4210454006493092\n",
      "epoch: 2\t|step: 7500\t|Loss: 0.4227552183866501\n",
      "epoch: 2\t|step: 8000\t|Loss: 0.4115293711125851\n",
      "epoch: 2\t|step: 8500\t|Loss: 0.4102249690592289\n",
      "epoch: 2\t|step: 9000\t|Loss: 0.4144041428565979\n",
      "epoch: 2\t|step: 9500\t|Loss: 0.41339958465099336\n",
      "epoch: 2\t|step: 10000\t|Loss: 0.4157183653414249\n",
      "epoch: 2\t|step: 10500\t|Loss: 0.4168036753535271\n",
      "epoch: 2\t|step: 11000\t|Loss: 0.41146279394626617\n",
      "epoch: 2\t|step: 11500\t|Loss: 0.4171846372783184\n",
      "epoch: 2\t|step: 12000\t|Loss: 0.4138368842303753\n",
      "epoch: 2\t|step: 12500\t|Loss: 0.414254325568676\n",
      "epoch: 2\t|step: 13000\t|Loss: 0.4138611359894276\n",
      "epoch: 2\t|step: 13500\t|Loss: 0.4170850030183792\n",
      "epoch: 2\t|step: 14000\t|Loss: 0.4117256487607956\n",
      "epoch: 2\t|step: 14500\t|Loss: 0.4194092089533806\n",
      "epoch: 2\t|step: 15000\t|Loss: 0.41675257340073585\n",
      "epoch: 2\t|step: 15500\t|Loss: 0.4154117750227451\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4335080853683921, 0.7820372104284816\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 3\t|step: 0\t|Loss: 0.001449864387512207\n",
      "epoch: 3\t|step: 500\t|Loss: 0.4146785242855549\n",
      "epoch: 3\t|step: 1000\t|Loss: 0.41731271159648897\n",
      "epoch: 3\t|step: 1500\t|Loss: 0.41302031433582304\n",
      "epoch: 3\t|step: 2000\t|Loss: 0.4117920286953449\n",
      "epoch: 3\t|step: 2500\t|Loss: 0.4176258564591408\n",
      "epoch: 3\t|step: 3000\t|Loss: 0.41721917444467543\n",
      "epoch: 3\t|step: 3500\t|Loss: 0.4156983525454998\n",
      "epoch: 3\t|step: 4000\t|Loss: 0.4107032204568386\n",
      "epoch: 3\t|step: 4500\t|Loss: 0.41306287440657613\n",
      "epoch: 3\t|step: 5000\t|Loss: 0.4088380382657051\n",
      "epoch: 3\t|step: 5500\t|Loss: 0.4127017800807953\n",
      "epoch: 3\t|step: 6000\t|Loss: 0.415493428170681\n",
      "epoch: 3\t|step: 6500\t|Loss: 0.4140955648422241\n",
      "epoch: 3\t|step: 7000\t|Loss: 0.4141399884223938\n",
      "epoch: 3\t|step: 7500\t|Loss: 0.4110486988425255\n",
      "epoch: 3\t|step: 8000\t|Loss: 0.4125916966497898\n",
      "epoch: 3\t|step: 8500\t|Loss: 0.4135023685395718\n",
      "epoch: 3\t|step: 9000\t|Loss: 0.4164598419964313\n",
      "epoch: 3\t|step: 9500\t|Loss: 0.41012002232670786\n",
      "epoch: 3\t|step: 10000\t|Loss: 0.4123885360062122\n",
      "epoch: 3\t|step: 10500\t|Loss: 0.41671181812882424\n",
      "epoch: 3\t|step: 11000\t|Loss: 0.4101665549874306\n",
      "epoch: 3\t|step: 11500\t|Loss: 0.4127060144543648\n",
      "epoch: 3\t|step: 12000\t|Loss: 0.40761445823311804\n",
      "epoch: 3\t|step: 12500\t|Loss: 0.4123526370823383\n",
      "epoch: 3\t|step: 13000\t|Loss: 0.41120800736546514\n",
      "epoch: 3\t|step: 13500\t|Loss: 0.4085160918235779\n",
      "epoch: 3\t|step: 14000\t|Loss: 0.41016228663921356\n",
      "epoch: 3\t|step: 14500\t|Loss: 0.4062673111855984\n",
      "epoch: 3\t|step: 15000\t|Loss: 0.4123310305774212\n",
      "epoch: 3\t|step: 15500\t|Loss: 0.40963302040100097\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4355984430111409, 0.7821092275372417\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 4\t|step: 0\t|Loss: 0.000844821035861969\n",
      "epoch: 4\t|step: 500\t|Loss: 0.41210651019215583\n",
      "epoch: 4\t|step: 1000\t|Loss: 0.4069806786775589\n",
      "epoch: 4\t|step: 1500\t|Loss: 0.4141248045563698\n",
      "epoch: 4\t|step: 2000\t|Loss: 0.4098191132545471\n",
      "epoch: 4\t|step: 2500\t|Loss: 0.4071894224882126\n",
      "epoch: 4\t|step: 3000\t|Loss: 0.411216407507658\n",
      "epoch: 4\t|step: 3500\t|Loss: 0.41112905073165895\n",
      "epoch: 4\t|step: 4000\t|Loss: 0.4094794000387192\n",
      "epoch: 4\t|step: 4500\t|Loss: 0.40995321261882783\n",
      "epoch: 4\t|step: 5000\t|Loss: 0.4085399594902992\n",
      "epoch: 4\t|step: 5500\t|Loss: 0.4115160518884659\n",
      "epoch: 4\t|step: 6000\t|Loss: 0.4118977920413017\n",
      "epoch: 4\t|step: 6500\t|Loss: 0.41343324828147887\n",
      "epoch: 4\t|step: 7000\t|Loss: 0.40725317814946177\n",
      "epoch: 4\t|step: 7500\t|Loss: 0.4098400757014751\n",
      "epoch: 4\t|step: 8000\t|Loss: 0.40725095772743225\n",
      "epoch: 4\t|step: 8500\t|Loss: 0.40389373260736466\n",
      "epoch: 4\t|step: 9000\t|Loss: 0.4159917465150356\n",
      "epoch: 4\t|step: 9500\t|Loss: 0.4096406053602695\n",
      "epoch: 4\t|step: 10000\t|Loss: 0.4113408257961273\n",
      "epoch: 4\t|step: 10500\t|Loss: 0.4122906467318535\n",
      "epoch: 4\t|step: 11000\t|Loss: 0.4071493137478828\n",
      "epoch: 4\t|step: 11500\t|Loss: 0.41043922874331473\n",
      "epoch: 4\t|step: 12000\t|Loss: 0.40895280009508134\n",
      "epoch: 4\t|step: 12500\t|Loss: 0.4101916461288929\n",
      "epoch: 4\t|step: 13000\t|Loss: 0.4065711567997932\n",
      "epoch: 4\t|step: 13500\t|Loss: 0.4071234499514103\n",
      "epoch: 4\t|step: 14000\t|Loss: 0.40489943951368335\n",
      "epoch: 4\t|step: 14500\t|Loss: 0.406359699100256\n",
      "epoch: 4\t|step: 15000\t|Loss: 0.40607843098044394\n",
      "epoch: 4\t|step: 15500\t|Loss: 0.4084036167860031\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4343403430880887, 0.7810238732151407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\t|step: 0\t|Loss: 0.0007636753320693969\n",
      "epoch: 5\t|step: 500\t|Loss: 0.4120356779098511\n",
      "epoch: 5\t|step: 1000\t|Loss: 0.4109518237411976\n",
      "epoch: 5\t|step: 1500\t|Loss: 0.4130598160624504\n",
      "epoch: 5\t|step: 2000\t|Loss: 0.4043490433692932\n",
      "epoch: 5\t|step: 2500\t|Loss: 0.4063384031653404\n",
      "epoch: 5\t|step: 3000\t|Loss: 0.40149230206012726\n",
      "epoch: 5\t|step: 3500\t|Loss: 0.4068253464996815\n",
      "epoch: 5\t|step: 4000\t|Loss: 0.4077712162435055\n",
      "epoch: 5\t|step: 4500\t|Loss: 0.40994946271181104\n",
      "epoch: 5\t|step: 5000\t|Loss: 0.40773230335116384\n",
      "epoch: 5\t|step: 5500\t|Loss: 0.4060909429490566\n",
      "epoch: 5\t|step: 6000\t|Loss: 0.40883349353075027\n",
      "epoch: 5\t|step: 6500\t|Loss: 0.4074384981095791\n",
      "epoch: 5\t|step: 7000\t|Loss: 0.4044948096871376\n",
      "epoch: 5\t|step: 7500\t|Loss: 0.4060280070304871\n",
      "epoch: 5\t|step: 8000\t|Loss: 0.40950706219673155\n",
      "epoch: 5\t|step: 8500\t|Loss: 0.4028385805785656\n",
      "epoch: 5\t|step: 9000\t|Loss: 0.4080126234292984\n",
      "epoch: 5\t|step: 9500\t|Loss: 0.41048034632205965\n",
      "epoch: 5\t|step: 10000\t|Loss: 0.4065168502628803\n",
      "epoch: 5\t|step: 10500\t|Loss: 0.4017393225133419\n",
      "epoch: 5\t|step: 11000\t|Loss: 0.4059691521525383\n",
      "epoch: 5\t|step: 11500\t|Loss: 0.40931931751966477\n",
      "epoch: 5\t|step: 12000\t|Loss: 0.40926852703094485\n",
      "epoch: 5\t|step: 12500\t|Loss: 0.4078544952869415\n",
      "epoch: 5\t|step: 13000\t|Loss: 0.40670815485715867\n",
      "epoch: 5\t|step: 13500\t|Loss: 0.40829550462961195\n",
      "epoch: 5\t|step: 14000\t|Loss: 0.4116607789993286\n",
      "epoch: 5\t|step: 14500\t|Loss: 0.40677655562758447\n",
      "epoch: 5\t|step: 15000\t|Loss: 0.40393722370266916\n",
      "epoch: 5\t|step: 15500\t|Loss: 0.4038258293271065\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4330530629460964, 0.7816773255646869\n",
      "epoch: 6\t|step: 0\t|Loss: 0.000953873872756958\n",
      "epoch: 6\t|step: 500\t|Loss: 0.39654752537608146\n",
      "epoch: 6\t|step: 1000\t|Loss: 0.4051705215573311\n",
      "epoch: 6\t|step: 1500\t|Loss: 0.40192159813642503\n",
      "epoch: 6\t|step: 2000\t|Loss: 0.40845276683568954\n",
      "epoch: 6\t|step: 2500\t|Loss: 0.40780225598812103\n",
      "epoch: 6\t|step: 3000\t|Loss: 0.4052837556898594\n",
      "epoch: 6\t|step: 3500\t|Loss: 0.41162836173176764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fd10134e598>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-1f6535c0788f>\", line 3, in <module>\n",
      "    train(e, trainData, model, likelihood,optim)\n",
      "  File \"<ipython-input-14-6ad33a079278>\", line 36, in train\n",
      "    optim.step()\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/pytorch_pretrained_bert/optimization.py\", line 292, in step\n",
      "    update_with_lr = lr_scheduled * update\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/yikuan/anaconda/envs/py3/lib/python3.7/posixpath.py\", line 80, in join\n",
      "    a = os.fspath(a)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "best_pre = 0\n",
    "for e in range(20):\n",
    "    train(e, trainData, model, likelihood,optim)\n",
    "#     auc_train, time_cost_train = evaluation(trainData, model)\n",
    "    auc_test, auc_score = evaluation(testData, model, likelihood)\n",
    "#     tempprc, score, y, y_label, variance_list, patid_list, age_list, epis_list, alea_list, predictive_list = evaluation_GP(testData, model, likelihood, trainConfig.device, 40)\n",
    "\n",
    "    print('test precision: {}, {}'.format(auc_test, auc_score))\n",
    "    if auc_test >best_pre:\n",
    "        # Save a trained model\n",
    "        output_model_file = os.path.join(trainConfig.output_dir, trainConfig.best_name)\n",
    "        create_folder(trainConfig.output_dir)\n",
    "        save_model(output_model_file, model)\n",
    "        best_pre = auc_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
