{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/yikuan/project/Code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.pytorch import save_model\n",
    "from common.common import create_folder, load_obj\n",
    "import os\n",
    "import torch\n",
    "from ACM.model.utils.utils import age_vocab\n",
    "import pandas as pd\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from ACM.dataLoader.HF import HF_data\n",
    "from ACM.model.bertKISSGP import BertHF\n",
    "import gpytorch\n",
    "from ACM.model.optimiser import adam\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.num_labels = config.get('num_labels')\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    'vocab':'/home/yikuan/project/Code/ACM/data/Full_vocab',\n",
    "    'train': '/home/shared/yikuan/ACM/data/Depression/Depression_clean_train.parquet',\n",
    "    'test': '/home/shared/yikuan/ACM/data/Depression/Depression_clean_test.parquet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 256,\n",
    "    'max_age': 110,\n",
    "    'month': 1,\n",
    "    'age_symbol': None,\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertVocab = load_obj(file_config['vocab'])\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon=global_params['month'], symbol=global_params['age_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_raw = pd.read_parquet(file_config['train']).reset_index(drop=True)\n",
    "testData_raw = pd.read_parquet(file_config['test']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': 64,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'train_loader_workers': 3,\n",
    "    'test_loader_workers': 3,\n",
    "    'device': 'cuda:0',\n",
    "    'output_dir': '/home/shared/yikuan/ACM/model/Depression',\n",
    "    'output_name': 'behrtKISSGP.bin',\n",
    "    'best_name': 'behrtKISSGP_best.bin',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainConfig = TrainConfig(train_params)\n",
    "\n",
    "data_set = HF_data(trainConfig, trainData_raw, testData_raw, BertVocab['token2idx'], ageVocab, code='code', age='age')\n",
    "\n",
    "trainData = data_set.get_weighted_sample_train(4)\n",
    "testData = data_set.get_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),\n",
    "    'hidden_size': 150,\n",
    "    'num_hidden_layers': 4,\n",
    "    'num_attention_heads': 6,\n",
    "    'hidden_act': 'gelu',\n",
    "    'intermediate_size': 108,\n",
    "    'max_position_embeddings': global_params['max_seq_len'],\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'prior_prec': 1e0,\n",
    "    'prec_init': 1e0,\n",
    "    'initializer_range': 0.02,\n",
    "    'num_labels': 1,\n",
    "    'hidden_dropout_prob': 0.29,\n",
    "    'attention_probs_dropout_prob': 0.38\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfig = BertConfig(model_param)\n",
    "\n",
    "model = BertHF(modelConfig, n_dim=24,grid_size=40, ard_num_dims=24)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.BernoulliLikelihood().to(trainConfig.device)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=len(trainData.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "def load_model(path, model):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and k not in ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "model = load_model('/home/shared/yikuan/HF/MLM/PureICD_diag_med.bin', model)\n",
    "model = model.to(trainConfig.device)\n",
    "optim = adam(list(model.named_parameters()),config=optim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    label, output=label.cpu(), output.detach().cpu()\n",
    "    tempprc= average_precision_score(label.numpy(),output.numpy())\n",
    "    auc = roc_auc_score(label.numpy(),output.numpy())\n",
    "    return tempprc, output, label\n",
    "\n",
    "def precision_test(logits, label):\n",
    "#     sig = nn.Sigmoid()\n",
    "#     output=sig(logits)\n",
    "    tempprc= average_precision_score(label.numpy(),logits.numpy())\n",
    "    auc = roc_auc_score(label.numpy(),logits.numpy())\n",
    "    return tempprc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, trainload, model, likelihood, optim):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    for step, batch in enumerate(trainload):\n",
    "        cnt += 1\n",
    "\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _, _ = batch\n",
    "\n",
    "        age_ids = age_ids.to(train_params['device'])\n",
    "        input_ids = input_ids.to(train_params['device'])\n",
    "        posi_ids = posi_ids.to(train_params['device'])\n",
    "        segment_ids = segment_ids.to(train_params['device'])\n",
    "        attMask = attMask.to(train_params['device'])\n",
    "        targets = targets.view(-1).to(train_params['device'])\n",
    "\n",
    "        output = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets)\n",
    "        loss = -mll(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            #             prec, a, b = precision(logits, targets)\n",
    "            #             print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| precision: {}\".format(e, cnt, temp_loss / 500, prec))\n",
    "            print(\"epoch: {}\\t|step: {}\\t|Loss: {}\".format(e, step, temp_loss / 500))\n",
    "            temp_loss = 0\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    # Save a trained model\n",
    "    output_model_file = os.path.join(trainConfig.output_dir, trainConfig.output_name)\n",
    "    create_folder(trainConfig.output_dir)\n",
    "    save_model(output_model_file, model)\n",
    "\n",
    "\n",
    "def evaluation(testload, model, likelihood):\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            age_ids, input_ids, posi_ids, segment_ids, attMask, targets, _, _ = batch\n",
    "\n",
    "            age_ids = age_ids.to(train_params['device'])\n",
    "            input_ids = input_ids.to(train_params['device'])\n",
    "            posi_ids = posi_ids.to(train_params['device'])\n",
    "            segment_ids = segment_ids.to(train_params['device'])\n",
    "            attMask = attMask.to(train_params['device'])\n",
    "            targets = targets.view(-1).to(train_params['device'])\n",
    "\n",
    "            output = likelihood(\n",
    "                model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask, labels=targets))\n",
    "\n",
    "            logits = output.mean.float().cpu()\n",
    "            targets = targets.cpu()\n",
    "\n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "\n",
    "        y_label = torch.cat(y_label, dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "\n",
    "        tempprc, auc = precision_test(y.view(-1), y_label.view(-1))\n",
    "        return tempprc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t|step: 0\t|Loss: 0.008768121719360351\n",
      "epoch: 0\t|step: 500\t|Loss: 3.804774790763855\n",
      "epoch: 0\t|step: 1500\t|Loss: 2.9021462812423704\n",
      "epoch: 0\t|step: 2000\t|Loss: 2.7255283317565917\n",
      "epoch: 0\t|step: 2500\t|Loss: 2.6061324028968813\n",
      "epoch: 0\t|step: 3000\t|Loss: 2.5140697963237764\n",
      "epoch: 0\t|step: 3500\t|Loss: 2.420725441932678\n",
      "epoch: 0\t|step: 4000\t|Loss: 2.2917193882465363\n",
      "epoch: 0\t|step: 4500\t|Loss: 2.1990071861743927\n",
      "epoch: 0\t|step: 5000\t|Loss: 2.080232113599777\n",
      "epoch: 0\t|step: 5500\t|Loss: 1.9751528468132018\n",
      "epoch: 0\t|step: 6000\t|Loss: 1.888222297668457\n",
      "epoch: 0\t|step: 6500\t|Loss: 1.8062055149078369\n",
      "epoch: 0\t|step: 7000\t|Loss: 1.7255313392877578\n",
      "epoch: 0\t|step: 7500\t|Loss: 1.6390013983249665\n",
      "epoch: 0\t|step: 8000\t|Loss: 1.5826390161514283\n",
      "epoch: 0\t|step: 8500\t|Loss: 1.5191547157764436\n",
      "epoch: 0\t|step: 9000\t|Loss: 1.4799510362148285\n",
      "epoch: 0\t|step: 9500\t|Loss: 1.3793616534471511\n",
      "epoch: 0\t|step: 10000\t|Loss: 1.3217113312482833\n",
      "epoch: 0\t|step: 10500\t|Loss: 1.281630457162857\n",
      "epoch: 0\t|step: 11000\t|Loss: 1.2172562601566315\n",
      "epoch: 0\t|step: 11500\t|Loss: 1.1662277492284774\n",
      "epoch: 0\t|step: 12000\t|Loss: 1.1093060804605483\n",
      "epoch: 0\t|step: 12500\t|Loss: 1.0652900661230087\n",
      "epoch: 0\t|step: 13000\t|Loss: 1.009003010749817\n",
      "epoch: 0\t|step: 13500\t|Loss: 0.949684406042099\n",
      "epoch: 0\t|step: 14000\t|Loss: 0.9126670286655426\n",
      "epoch: 0\t|step: 14500\t|Loss: 0.8651589031219482\n",
      "epoch: 0\t|step: 15000\t|Loss: 0.8232647436857223\n",
      "epoch: 0\t|step: 15500\t|Loss: 0.7830622236728668\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4130945574458488, 0.7743404682157652\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 1\t|step: 0\t|Loss: 0.001280350685119629\n",
      "epoch: 1\t|step: 500\t|Loss: 0.7172702350020409\n",
      "epoch: 1\t|step: 1000\t|Loss: 0.6859563961625099\n",
      "epoch: 1\t|step: 1500\t|Loss: 0.6644228869676589\n",
      "epoch: 1\t|step: 2000\t|Loss: 0.6356683824062347\n",
      "epoch: 1\t|step: 2500\t|Loss: 0.6135769369006157\n",
      "epoch: 1\t|step: 3000\t|Loss: 0.587861337840557\n",
      "epoch: 1\t|step: 3500\t|Loss: 0.5718633908033371\n",
      "epoch: 1\t|step: 4000\t|Loss: 0.5461147521138191\n",
      "epoch: 1\t|step: 4500\t|Loss: 0.5295147201418877\n",
      "epoch: 1\t|step: 5000\t|Loss: 0.5213740922808647\n",
      "epoch: 1\t|step: 5500\t|Loss: 0.5033699389696121\n",
      "epoch: 1\t|step: 6000\t|Loss: 0.4937256574034691\n",
      "epoch: 1\t|step: 6500\t|Loss: 0.48321583873033525\n",
      "epoch: 1\t|step: 7000\t|Loss: 0.486439804315567\n",
      "epoch: 1\t|step: 7500\t|Loss: 0.4738832182884216\n",
      "epoch: 1\t|step: 8000\t|Loss: 0.4604944043159485\n",
      "epoch: 1\t|step: 8500\t|Loss: 0.45368239063024524\n",
      "epoch: 1\t|step: 9000\t|Loss: 0.4532339916825294\n",
      "epoch: 1\t|step: 9500\t|Loss: 0.4410961025953293\n",
      "epoch: 1\t|step: 10000\t|Loss: 0.43913294732570646\n",
      "epoch: 1\t|step: 10500\t|Loss: 0.44040175169706347\n",
      "epoch: 1\t|step: 11000\t|Loss: 0.44145141261816023\n",
      "epoch: 1\t|step: 11500\t|Loss: 0.43082150450348855\n",
      "epoch: 1\t|step: 12000\t|Loss: 0.4287451234459877\n",
      "epoch: 1\t|step: 12500\t|Loss: 0.4294194830954075\n",
      "epoch: 1\t|step: 13000\t|Loss: 0.42540775832533834\n",
      "epoch: 1\t|step: 13500\t|Loss: 0.4234481979608536\n",
      "epoch: 1\t|step: 14000\t|Loss: 0.4254760771691799\n",
      "epoch: 1\t|step: 14500\t|Loss: 0.4285956670045853\n",
      "epoch: 1\t|step: 15000\t|Loss: 0.42571734175086023\n",
      "epoch: 1\t|step: 15500\t|Loss: 0.4228866723179817\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4247730770931849, 0.7796521752867548\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 2\t|step: 0\t|Loss: 0.0008723903894424438\n",
      "epoch: 2\t|step: 500\t|Loss: 0.4295432427227497\n",
      "epoch: 2\t|step: 1000\t|Loss: 0.4240426985621452\n",
      "epoch: 2\t|step: 1500\t|Loss: 0.4172918242812157\n",
      "epoch: 2\t|step: 2000\t|Loss: 0.42462614870071413\n",
      "epoch: 2\t|step: 2500\t|Loss: 0.42125224658846855\n",
      "epoch: 2\t|step: 3000\t|Loss: 0.4221091927587986\n",
      "epoch: 2\t|step: 3500\t|Loss: 0.4165309471189976\n",
      "epoch: 2\t|step: 4000\t|Loss: 0.42336248791217806\n",
      "epoch: 2\t|step: 4500\t|Loss: 0.4161184757053852\n",
      "epoch: 2\t|step: 5000\t|Loss: 0.42541662257909774\n",
      "epoch: 2\t|step: 5500\t|Loss: 0.4188735441863537\n",
      "epoch: 2\t|step: 6000\t|Loss: 0.4187738161981106\n",
      "epoch: 2\t|step: 6500\t|Loss: 0.42096413841843605\n",
      "epoch: 2\t|step: 7000\t|Loss: 0.4138803997039795\n",
      "epoch: 2\t|step: 7500\t|Loss: 0.4209451393187046\n",
      "epoch: 2\t|step: 8000\t|Loss: 0.41299624121189116\n",
      "epoch: 2\t|step: 8500\t|Loss: 0.42162796792387963\n",
      "epoch: 2\t|step: 9000\t|Loss: 0.41713021099567416\n",
      "epoch: 2\t|step: 9500\t|Loss: 0.41697948443889615\n",
      "epoch: 2\t|step: 10000\t|Loss: 0.42083022701740264\n",
      "epoch: 2\t|step: 10500\t|Loss: 0.4179950782358646\n",
      "epoch: 2\t|step: 11000\t|Loss: 0.41273067936301233\n",
      "epoch: 2\t|step: 11500\t|Loss: 0.4191296921372414\n",
      "epoch: 2\t|step: 12000\t|Loss: 0.42328811940550803\n",
      "epoch: 2\t|step: 12500\t|Loss: 0.41921311205625533\n",
      "epoch: 2\t|step: 13000\t|Loss: 0.41879024377465246\n",
      "epoch: 2\t|step: 13500\t|Loss: 0.41549736008048055\n",
      "epoch: 2\t|step: 14000\t|Loss: 0.42153444212675095\n",
      "epoch: 2\t|step: 14500\t|Loss: 0.4191920624375343\n",
      "epoch: 2\t|step: 15000\t|Loss: 0.4162990282177925\n",
      "epoch: 2\t|step: 15500\t|Loss: 0.4180448784828186\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4318910572601926, 0.7815059371277026\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "epoch: 3\t|step: 0\t|Loss: 0.0008804587721824646\n",
      "epoch: 3\t|step: 500\t|Loss: 0.41616879764199255\n",
      "epoch: 3\t|step: 1000\t|Loss: 0.41648610278964043\n",
      "epoch: 3\t|step: 1500\t|Loss: 0.4254759812951088\n",
      "epoch: 3\t|step: 2000\t|Loss: 0.41192721542716026\n",
      "epoch: 3\t|step: 2500\t|Loss: 0.4205951150655746\n",
      "epoch: 3\t|step: 3000\t|Loss: 0.4112842856049538\n",
      "epoch: 3\t|step: 3500\t|Loss: 0.4159055733680725\n",
      "epoch: 3\t|step: 4000\t|Loss: 0.411701596647501\n",
      "epoch: 3\t|step: 4500\t|Loss: 0.42174727222323416\n",
      "epoch: 3\t|step: 5000\t|Loss: 0.42047813841700554\n",
      "epoch: 3\t|step: 5500\t|Loss: 0.4136227599680424\n",
      "epoch: 3\t|step: 6000\t|Loss: 0.41934334191679956\n",
      "epoch: 3\t|step: 6500\t|Loss: 0.4176840981543064\n",
      "epoch: 3\t|step: 7000\t|Loss: 0.4134001008272171\n",
      "epoch: 3\t|step: 7500\t|Loss: 0.4091382527053356\n",
      "epoch: 3\t|step: 8000\t|Loss: 0.41211781004071235\n",
      "epoch: 3\t|step: 8500\t|Loss: 0.4083786893188953\n",
      "epoch: 3\t|step: 9000\t|Loss: 0.4170672890841961\n",
      "epoch: 3\t|step: 9500\t|Loss: 0.4159148617088795\n",
      "epoch: 3\t|step: 10000\t|Loss: 0.41346108439564705\n",
      "epoch: 3\t|step: 10500\t|Loss: 0.4128803445696831\n",
      "epoch: 3\t|step: 11000\t|Loss: 0.4137383531332016\n",
      "epoch: 3\t|step: 11500\t|Loss: 0.41519084510207177\n",
      "epoch: 3\t|step: 12000\t|Loss: 0.401667959779501\n",
      "epoch: 3\t|step: 12500\t|Loss: 0.40857186111807825\n",
      "epoch: 3\t|step: 13000\t|Loss: 0.41626348996162416\n",
      "epoch: 3\t|step: 13500\t|Loss: 0.41491673165559767\n",
      "epoch: 3\t|step: 14000\t|Loss: 0.4105852282345295\n",
      "epoch: 3\t|step: 14500\t|Loss: 0.40832792210578917\n",
      "epoch: 3\t|step: 15000\t|Loss: 0.4099636116027832\n",
      "epoch: 3\t|step: 15500\t|Loss: 0.41165978309512136\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.43097717608781944, 0.7819525915029106\n",
      "epoch: 4\t|step: 0\t|Loss: 0.0007738537192344666\n",
      "epoch: 4\t|step: 500\t|Loss: 0.41004550057649614\n",
      "epoch: 4\t|step: 1000\t|Loss: 0.4127404444217682\n",
      "epoch: 4\t|step: 1500\t|Loss: 0.4144665730893612\n",
      "epoch: 4\t|step: 2000\t|Loss: 0.41157505637407304\n",
      "epoch: 4\t|step: 2500\t|Loss: 0.4116682604253292\n",
      "epoch: 4\t|step: 3000\t|Loss: 0.4121486283838749\n",
      "epoch: 4\t|step: 3500\t|Loss: 0.4080537545382977\n",
      "epoch: 4\t|step: 4000\t|Loss: 0.4131853291094303\n",
      "epoch: 4\t|step: 4500\t|Loss: 0.41860775572061537\n",
      "epoch: 4\t|step: 5000\t|Loss: 0.4125657896697521\n",
      "epoch: 4\t|step: 5500\t|Loss: 0.4120525997877121\n",
      "epoch: 4\t|step: 6000\t|Loss: 0.40733376634120944\n",
      "epoch: 4\t|step: 6500\t|Loss: 0.4075265394747257\n",
      "epoch: 4\t|step: 7000\t|Loss: 0.4099864031970501\n",
      "epoch: 4\t|step: 7500\t|Loss: 0.4062694560885429\n",
      "epoch: 4\t|step: 8000\t|Loss: 0.4105352638959885\n",
      "epoch: 4\t|step: 8500\t|Loss: 0.4193440103828907\n",
      "epoch: 4\t|step: 9000\t|Loss: 0.4105887800753117\n",
      "epoch: 4\t|step: 9500\t|Loss: 0.4103074907064438\n",
      "epoch: 4\t|step: 10000\t|Loss: 0.4111479345858097\n",
      "epoch: 4\t|step: 10500\t|Loss: 0.4097450200915337\n",
      "epoch: 4\t|step: 11000\t|Loss: 0.41091372358798983\n",
      "epoch: 4\t|step: 11500\t|Loss: 0.4161901248991489\n",
      "epoch: 4\t|step: 12000\t|Loss: 0.4068596425354481\n",
      "epoch: 4\t|step: 12500\t|Loss: 0.4157420057058334\n",
      "epoch: 4\t|step: 13000\t|Loss: 0.40742052227258685\n",
      "epoch: 4\t|step: 13500\t|Loss: 0.4112815173268318\n",
      "epoch: 4\t|step: 14000\t|Loss: 0.4099966460466385\n",
      "epoch: 4\t|step: 14500\t|Loss: 0.41142657351493833\n",
      "epoch: 4\t|step: 15000\t|Loss: 0.4130606529712677\n",
      "epoch: 4\t|step: 15500\t|Loss: 0.4103482320010662\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.433725215369004, 0.7820578990139014\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\t|step: 0\t|Loss: 0.0008092639446258545\n",
      "epoch: 5\t|step: 500\t|Loss: 0.41199562850594523\n",
      "epoch: 5\t|step: 1000\t|Loss: 0.4069055047929287\n",
      "epoch: 5\t|step: 1500\t|Loss: 0.4122260991036892\n",
      "epoch: 5\t|step: 2000\t|Loss: 0.41373373809456826\n",
      "epoch: 5\t|step: 2500\t|Loss: 0.41429139095544815\n",
      "epoch: 5\t|step: 3000\t|Loss: 0.41204263213276865\n",
      "epoch: 5\t|step: 3500\t|Loss: 0.4052334398329258\n",
      "epoch: 5\t|step: 4000\t|Loss: 0.40777027887105943\n",
      "epoch: 5\t|step: 4500\t|Loss: 0.40784852385520937\n",
      "epoch: 5\t|step: 5000\t|Loss: 0.41132773491740227\n",
      "epoch: 5\t|step: 5500\t|Loss: 0.40612172228097915\n",
      "epoch: 5\t|step: 6000\t|Loss: 0.4113026424050331\n",
      "epoch: 5\t|step: 6500\t|Loss: 0.4128769714832306\n",
      "epoch: 5\t|step: 7000\t|Loss: 0.41051990085840223\n",
      "epoch: 5\t|step: 7500\t|Loss: 0.4085178347826004\n",
      "epoch: 5\t|step: 8000\t|Loss: 0.4067641128897667\n",
      "epoch: 5\t|step: 8500\t|Loss: 0.4004742228090763\n",
      "epoch: 5\t|step: 9000\t|Loss: 0.41285968297719955\n",
      "epoch: 5\t|step: 9500\t|Loss: 0.41167802557349203\n",
      "epoch: 5\t|step: 10000\t|Loss: 0.4017868762910366\n",
      "epoch: 5\t|step: 10500\t|Loss: 0.4099760135710239\n",
      "epoch: 5\t|step: 11000\t|Loss: 0.40662278789281847\n",
      "epoch: 5\t|step: 11500\t|Loss: 0.4087172727584839\n",
      "epoch: 5\t|step: 12000\t|Loss: 0.4026092592775822\n",
      "epoch: 5\t|step: 12500\t|Loss: 0.40350714203715327\n",
      "epoch: 5\t|step: 13000\t|Loss: 0.4093458936214447\n",
      "epoch: 5\t|step: 13500\t|Loss: 0.4068341567516327\n",
      "epoch: 5\t|step: 14000\t|Loss: 0.4144919380247593\n",
      "epoch: 5\t|step: 14500\t|Loss: 0.41113941702246665\n",
      "epoch: 5\t|step: 15000\t|Loss: 0.4138535887300968\n",
      "epoch: 5\t|step: 15500\t|Loss: 0.40400104609131815\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4324779789369826, 0.780484637727807\n",
      "epoch: 6\t|step: 0\t|Loss: 0.0008284835815429687\n",
      "epoch: 6\t|step: 500\t|Loss: 0.41054277229309083\n",
      "epoch: 6\t|step: 1000\t|Loss: 0.409472638964653\n",
      "epoch: 6\t|step: 1500\t|Loss: 0.40498328432440756\n",
      "epoch: 6\t|step: 2000\t|Loss: 0.40492438024282457\n",
      "epoch: 6\t|step: 2500\t|Loss: 0.4098436742126942\n",
      "epoch: 6\t|step: 3000\t|Loss: 0.4068653093278408\n",
      "epoch: 6\t|step: 3500\t|Loss: 0.41169814425706863\n",
      "epoch: 6\t|step: 4000\t|Loss: 0.4053734622299671\n",
      "epoch: 6\t|step: 4500\t|Loss: 0.4070956518650055\n",
      "epoch: 6\t|step: 5000\t|Loss: 0.4031259732544422\n",
      "epoch: 6\t|step: 5500\t|Loss: 0.40782016813755034\n",
      "epoch: 6\t|step: 6000\t|Loss: 0.40149541389942167\n",
      "epoch: 6\t|step: 6500\t|Loss: 0.4103437440693378\n",
      "epoch: 6\t|step: 7000\t|Loss: 0.40377575388550757\n",
      "epoch: 6\t|step: 7500\t|Loss: 0.40153548401594163\n",
      "epoch: 6\t|step: 8000\t|Loss: 0.4095686161518097\n",
      "epoch: 6\t|step: 8500\t|Loss: 0.4104902364015579\n",
      "epoch: 6\t|step: 9000\t|Loss: 0.40876286989450455\n",
      "epoch: 6\t|step: 9500\t|Loss: 0.4121271781921387\n",
      "epoch: 6\t|step: 10000\t|Loss: 0.4022829228639603\n",
      "epoch: 6\t|step: 10500\t|Loss: 0.40584983256459234\n",
      "epoch: 6\t|step: 11000\t|Loss: 0.4095717667341232\n",
      "epoch: 6\t|step: 11500\t|Loss: 0.40305974382162096\n",
      "epoch: 6\t|step: 12000\t|Loss: 0.40522639974951746\n",
      "epoch: 6\t|step: 12500\t|Loss: 0.41105105125904084\n",
      "epoch: 6\t|step: 13000\t|Loss: 0.4049457713961601\n",
      "epoch: 6\t|step: 13500\t|Loss: 0.40432561782002446\n",
      "epoch: 6\t|step: 14000\t|Loss: 0.4026841384768486\n",
      "epoch: 6\t|step: 14500\t|Loss: 0.4071990160346031\n",
      "epoch: 6\t|step: 15000\t|Loss: 0.3986442398130894\n",
      "epoch: 6\t|step: 15500\t|Loss: 0.41051720386743545\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4288055027033697, 0.779846474206552\n",
      "epoch: 7\t|step: 0\t|Loss: 0.0009144560098648071\n",
      "epoch: 7\t|step: 500\t|Loss: 0.40808579939603806\n",
      "epoch: 7\t|step: 1000\t|Loss: 0.40388020330667496\n",
      "epoch: 7\t|step: 1500\t|Loss: 0.4086189384460449\n",
      "epoch: 7\t|step: 2000\t|Loss: 0.4099668469130993\n",
      "epoch: 7\t|step: 2500\t|Loss: 0.40272199755907057\n",
      "epoch: 7\t|step: 3000\t|Loss: 0.4056435604989529\n",
      "epoch: 7\t|step: 3500\t|Loss: 0.3991417624950409\n",
      "epoch: 7\t|step: 4000\t|Loss: 0.4079744865596294\n",
      "epoch: 7\t|step: 4500\t|Loss: 0.4059532350301743\n",
      "epoch: 7\t|step: 5000\t|Loss: 0.4072615168094635\n",
      "epoch: 7\t|step: 5500\t|Loss: 0.40695800849795344\n",
      "epoch: 7\t|step: 6000\t|Loss: 0.4057822599709034\n",
      "epoch: 7\t|step: 6500\t|Loss: 0.4050196216106415\n",
      "epoch: 7\t|step: 7000\t|Loss: 0.41402062568068504\n",
      "epoch: 7\t|step: 7500\t|Loss: 0.40492869970202444\n",
      "epoch: 7\t|step: 8000\t|Loss: 0.40744085124135015\n",
      "epoch: 7\t|step: 8500\t|Loss: 0.4040905250310898\n",
      "epoch: 7\t|step: 9000\t|Loss: 0.40730955776572225\n",
      "epoch: 7\t|step: 9500\t|Loss: 0.4047297960817814\n",
      "epoch: 7\t|step: 10000\t|Loss: 0.4114062796533108\n",
      "epoch: 7\t|step: 10500\t|Loss: 0.40137143614888193\n",
      "epoch: 7\t|step: 11000\t|Loss: 0.39915588149428366\n",
      "epoch: 7\t|step: 11500\t|Loss: 0.4055793270766735\n",
      "epoch: 7\t|step: 12000\t|Loss: 0.4064773503243923\n",
      "epoch: 7\t|step: 12500\t|Loss: 0.4022580565214157\n",
      "epoch: 7\t|step: 13000\t|Loss: 0.40536682796478274\n",
      "epoch: 7\t|step: 13500\t|Loss: 0.40177095821499825\n",
      "epoch: 7\t|step: 14000\t|Loss: 0.404243339151144\n",
      "epoch: 7\t|step: 14500\t|Loss: 0.40896896067261695\n",
      "epoch: 7\t|step: 15000\t|Loss: 0.4020509802401066\n",
      "epoch: 7\t|step: 15500\t|Loss: 0.4077697061598301\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.42274956972555133, 0.7767895926758941\n",
      "epoch: 8\t|step: 0\t|Loss: 0.000874268651008606\n",
      "epoch: 8\t|step: 500\t|Loss: 0.40791349187493325\n",
      "epoch: 8\t|step: 1000\t|Loss: 0.4074758789241314\n",
      "epoch: 8\t|step: 1500\t|Loss: 0.40201593986153605\n",
      "epoch: 8\t|step: 2000\t|Loss: 0.4022534834742546\n",
      "epoch: 8\t|step: 2500\t|Loss: 0.4007731424868107\n",
      "epoch: 8\t|step: 3000\t|Loss: 0.3978094579577446\n",
      "epoch: 8\t|step: 3500\t|Loss: 0.405263663649559\n",
      "epoch: 8\t|step: 4000\t|Loss: 0.4019502122700214\n",
      "epoch: 8\t|step: 4500\t|Loss: 0.40542070955038073\n",
      "epoch: 8\t|step: 5000\t|Loss: 0.402617895424366\n",
      "epoch: 8\t|step: 5500\t|Loss: 0.40360348075628283\n",
      "epoch: 8\t|step: 6000\t|Loss: 0.401404560059309\n",
      "epoch: 8\t|step: 6500\t|Loss: 0.4039287346601486\n",
      "epoch: 8\t|step: 7000\t|Loss: 0.39874065092206\n",
      "epoch: 8\t|step: 7500\t|Loss: 0.40294932237267495\n",
      "epoch: 8\t|step: 8000\t|Loss: 0.4037593673765659\n",
      "epoch: 8\t|step: 8500\t|Loss: 0.40251616305112836\n",
      "epoch: 8\t|step: 9000\t|Loss: 0.3978765310049057\n",
      "epoch: 8\t|step: 9500\t|Loss: 0.3963177729845047\n",
      "epoch: 8\t|step: 10000\t|Loss: 0.39857111287117003\n",
      "epoch: 8\t|step: 10500\t|Loss: 0.40125693491101266\n",
      "epoch: 8\t|step: 11000\t|Loss: 0.40174938476085664\n",
      "epoch: 8\t|step: 11500\t|Loss: 0.4001550106406212\n",
      "epoch: 8\t|step: 12000\t|Loss: 0.4025874119400978\n",
      "epoch: 8\t|step: 12500\t|Loss: 0.39675031954050066\n",
      "epoch: 8\t|step: 13000\t|Loss: 0.40575270929932594\n",
      "epoch: 8\t|step: 13500\t|Loss: 0.40142133593559265\n",
      "epoch: 8\t|step: 14000\t|Loss: 0.3976466794312\n",
      "epoch: 8\t|step: 14500\t|Loss: 0.4014596547186375\n",
      "epoch: 8\t|step: 15000\t|Loss: 0.3995585601627827\n",
      "epoch: 8\t|step: 15500\t|Loss: 0.40318150812387465\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4270931295375003, 0.7779555947034507\n",
      "epoch: 9\t|step: 0\t|Loss: 0.000913823664188385\n",
      "epoch: 9\t|step: 500\t|Loss: 0.4017298988103867\n",
      "epoch: 9\t|step: 1000\t|Loss: 0.40116959723830226\n",
      "epoch: 9\t|step: 1500\t|Loss: 0.3970682126879692\n",
      "epoch: 9\t|step: 2000\t|Loss: 0.4055834609270096\n",
      "epoch: 9\t|step: 2500\t|Loss: 0.3993103182911873\n",
      "epoch: 9\t|step: 3000\t|Loss: 0.4042698537111282\n",
      "epoch: 9\t|step: 3500\t|Loss: 0.4013275152742863\n",
      "epoch: 9\t|step: 4000\t|Loss: 0.40056244665384294\n",
      "epoch: 9\t|step: 4500\t|Loss: 0.40648843187093736\n",
      "epoch: 9\t|step: 5000\t|Loss: 0.40075383937358855\n",
      "epoch: 9\t|step: 5500\t|Loss: 0.4016494633853436\n",
      "epoch: 9\t|step: 6000\t|Loss: 0.4012135885953903\n",
      "epoch: 9\t|step: 6500\t|Loss: 0.40398202058672905\n",
      "epoch: 9\t|step: 7000\t|Loss: 0.4043905383348465\n",
      "epoch: 9\t|step: 7500\t|Loss: 0.40177161133289335\n",
      "epoch: 9\t|step: 8000\t|Loss: 0.3997335387468338\n",
      "epoch: 9\t|step: 8500\t|Loss: 0.40258414852619173\n",
      "epoch: 9\t|step: 9000\t|Loss: 0.39917388516664504\n",
      "epoch: 9\t|step: 9500\t|Loss: 0.3932446335554123\n",
      "epoch: 9\t|step: 10000\t|Loss: 0.40050431457161906\n",
      "epoch: 9\t|step: 10500\t|Loss: 0.4030714272558689\n",
      "epoch: 9\t|step: 11000\t|Loss: 0.40459918573498727\n",
      "epoch: 9\t|step: 11500\t|Loss: 0.4002185370028019\n",
      "epoch: 9\t|step: 12000\t|Loss: 0.40343009197711943\n",
      "epoch: 9\t|step: 12500\t|Loss: 0.4018485088646412\n",
      "epoch: 9\t|step: 13000\t|Loss: 0.3971477082967758\n",
      "epoch: 9\t|step: 13500\t|Loss: 0.39917637902498243\n",
      "epoch: 9\t|step: 14000\t|Loss: 0.4000076379776001\n",
      "epoch: 9\t|step: 14500\t|Loss: 0.3998349939584732\n",
      "epoch: 9\t|step: 15000\t|Loss: 0.40077188074588777\n",
      "epoch: 9\t|step: 15500\t|Loss: 0.40340159222483635\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.42961674149243134, 0.7773914976260227\n",
      "epoch: 10\t|step: 0\t|Loss: 0.0007770201563835144\n",
      "epoch: 10\t|step: 500\t|Loss: 0.39760880294442175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\t|step: 1000\t|Loss: 0.39370824828743933\n",
      "epoch: 10\t|step: 1500\t|Loss: 0.4066557643711567\n",
      "epoch: 10\t|step: 2000\t|Loss: 0.39464907044172287\n",
      "epoch: 10\t|step: 2500\t|Loss: 0.4070910278856754\n",
      "epoch: 10\t|step: 3000\t|Loss: 0.3966818631887436\n",
      "epoch: 10\t|step: 3500\t|Loss: 0.4002802145779133\n",
      "epoch: 10\t|step: 4000\t|Loss: 0.3974001688659191\n",
      "epoch: 10\t|step: 4500\t|Loss: 0.4024540068805218\n",
      "epoch: 10\t|step: 5000\t|Loss: 0.3989296560287476\n",
      "epoch: 10\t|step: 5500\t|Loss: 0.3997889396250248\n",
      "epoch: 10\t|step: 6000\t|Loss: 0.3959154840409756\n",
      "epoch: 10\t|step: 6500\t|Loss: 0.395023844152689\n",
      "epoch: 10\t|step: 7000\t|Loss: 0.40415511006116867\n",
      "epoch: 10\t|step: 7500\t|Loss: 0.3998586537539959\n",
      "epoch: 10\t|step: 8000\t|Loss: 0.39782161632180213\n",
      "epoch: 10\t|step: 8500\t|Loss: 0.4029886754751205\n",
      "epoch: 10\t|step: 9000\t|Loss: 0.3995700365900993\n",
      "epoch: 10\t|step: 9500\t|Loss: 0.39412993550300596\n",
      "epoch: 10\t|step: 10000\t|Loss: 0.3980654469430447\n",
      "epoch: 10\t|step: 10500\t|Loss: 0.392073753207922\n",
      "epoch: 10\t|step: 11000\t|Loss: 0.4003051891326904\n",
      "epoch: 10\t|step: 11500\t|Loss: 0.3965947362184524\n",
      "epoch: 10\t|step: 12000\t|Loss: 0.3997961801290512\n",
      "epoch: 10\t|step: 12500\t|Loss: 0.40192284181714055\n",
      "epoch: 10\t|step: 13000\t|Loss: 0.4020062241256237\n",
      "epoch: 10\t|step: 13500\t|Loss: 0.4034321629703045\n",
      "epoch: 10\t|step: 14000\t|Loss: 0.392378372579813\n",
      "epoch: 10\t|step: 14500\t|Loss: 0.39483910343050954\n",
      "epoch: 10\t|step: 15000\t|Loss: 0.4031972364783287\n",
      "epoch: 10\t|step: 15500\t|Loss: 0.40301350674033165\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "test precision: 0.4179995946803146, 0.7748901366798608\n",
      "epoch: 11\t|step: 0\t|Loss: 0.0007955535650253296\n",
      "epoch: 11\t|step: 500\t|Loss: 0.3954331068098545\n",
      "epoch: 11\t|step: 1000\t|Loss: 0.39641216656565664\n",
      "epoch: 11\t|step: 1500\t|Loss: 0.3976769814491272\n",
      "epoch: 11\t|step: 2000\t|Loss: 0.3933570232987404\n",
      "epoch: 11\t|step: 2500\t|Loss: 0.3925261067152023\n",
      "epoch: 11\t|step: 3000\t|Loss: 0.4027367396354675\n",
      "epoch: 11\t|step: 3500\t|Loss: 0.392414578050375\n",
      "epoch: 11\t|step: 4000\t|Loss: 0.396246896058321\n",
      "epoch: 11\t|step: 4500\t|Loss: 0.40031115579605103\n",
      "epoch: 11\t|step: 5000\t|Loss: 0.39977243047952654\n",
      "epoch: 11\t|step: 5500\t|Loss: 0.39778457427024844\n",
      "epoch: 11\t|step: 6000\t|Loss: 0.40328146108984947\n",
      "epoch: 11\t|step: 6500\t|Loss: 0.39282047462463376\n",
      "epoch: 11\t|step: 7000\t|Loss: 0.3979870106577873\n",
      "epoch: 11\t|step: 7500\t|Loss: 0.39567700478434564\n",
      "epoch: 11\t|step: 8000\t|Loss: 0.3969118314981461\n",
      "epoch: 11\t|step: 8500\t|Loss: 0.39455806341767313\n",
      "epoch: 11\t|step: 9000\t|Loss: 0.40046254110336305\n",
      "epoch: 11\t|step: 9500\t|Loss: 0.3893238718807697\n",
      "epoch: 11\t|step: 10000\t|Loss: 0.4009172978401184\n",
      "epoch: 11\t|step: 10500\t|Loss: 0.3992693111896515\n",
      "epoch: 11\t|step: 11000\t|Loss: 0.39720357993245126\n",
      "epoch: 11\t|step: 11500\t|Loss: 0.4056753991544247\n",
      "epoch: 11\t|step: 12000\t|Loss: 0.3944024945795536\n",
      "epoch: 11\t|step: 12500\t|Loss: 0.39415209433436393\n",
      "epoch: 11\t|step: 13000\t|Loss: 0.40043715965747834\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f4738a315751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#     auc_train, time_cost_train = evaluation(trainData, model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mauc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8b4891b9f522>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(e, trainload, model, likelihood, optim)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposi_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattMask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/Code/ACM/model/bertKISSGP.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, age_ids, seg_ids, posi_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposi_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposi_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_bounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/Code/ACM/model/bertKISSGP.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, age_ids, seg_ids, posi_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    118\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    119\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_pre = 0\n",
    "for e in range(20):\n",
    "    train(e, trainData, model, likelihood,optim)\n",
    "#     auc_train, time_cost_train = evaluation(trainData, model)\n",
    "    auc_test, auc = evaluation(testData, model, likelihood)\n",
    "    print('test precision: {}, {}'.format(auc_test, auc))\n",
    "    if auc_test >best_pre:\n",
    "        # Save a trained model\n",
    "        output_model_file = os.path.join(trainConfig.output_dir, trainConfig.best_name)\n",
    "        create_folder(trainConfig.output_dir)\n",
    "        save_model(output_model_file, model)\n",
    "        best_pre = auc_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
