{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from evaluation.metrics import calibration,distributions_js, reliability_curve, expected_calibration_error, accuracy_confidence, roc_confidence\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score,accuracy_score\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import torch\n",
    "from common.common import load_obj, H5Recorder\n",
    "import pyro.distributions as distribution\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import seaborn as sns\n",
    "import torch.distributions as dist\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileConfig = {\n",
    "    'BEHRT': '',\n",
    "    'Whitened-GP':'',\n",
    "    'KISS-GP':'',\n",
    "    'BE':'',\n",
    "    'DBGP': '',\n",
    "    'BO': '',\n",
    "    'BE+BO': ''\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    'BEHRT': 'b',\n",
    "    'Whitened-GP':'g',\n",
    "    'KISS-GP':'c',\n",
    "    'BE':'orange',\n",
    "    'DBGP': 'r',\n",
    "    'BO': 'y',\n",
    "    'BE+BO': 'pink'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC\n",
    "for k,v in fileConfig.items():\n",
    "    recorder = H5Recorder(v)\n",
    "    recorder.open(read=True)\n",
    "    label = recorder.read('label')\n",
    "    prob = recorder.read('prob')\n",
    "    \n",
    "    if k not in ['BEHRT']:\n",
    "        # AUROC of mean of predictive probabilities\n",
    "        prob_mean = np.mean(prob, axis=1).reshape(-1)\n",
    "        print('AUROC {}: {}'.format(k, roc_auc_score(y_true=label, y_score=prob_mean)))\n",
    "        \n",
    "        print('AUPRC {}: {}'.format(k, average_precision_score(y_true=label, y_score=prob_mean)))\n",
    "    elif k in ['BEHRT']:\n",
    "        print('AUROC {}: {}'.format(k, roc_auc_score(y_true=label, y_score=prob)))\n",
    "        print('AUPRC {}: {}'.format(k, average_precision_score(y_true=label, y_score=prob)))\n",
    "    recorder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\n",
    "    'font.size':15,\n",
    "    'axes.labelsize':20,\n",
    "    'xtick.labelsize':15,\n",
    "    'ytick.labelsize': 15\n",
    "}\n",
    "\n",
    "matplotlib.rcParams.update(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy over confidence\n",
    "plt.figure(figsize=(10, 3))\n",
    "bins = 20\n",
    "\n",
    "for k,v in fileConfig.items():\n",
    "    recorder = H5Recorder(v)\n",
    "    recorder.open(read=True)\n",
    "    label = recorder.read('label')\n",
    "    prob = recorder.read('prob')\n",
    "    \n",
    "    if k not in ['BEHRT']:\n",
    "        # AUROC of mean of predictive probabilities\n",
    "        prob_mean = np.mean(prob, axis=1).reshape(-1)\n",
    "        \n",
    "        x, y = accuracy_confidence(prob_mean,label, bins)\n",
    "        idx = ~np.isnan(y)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "        \n",
    "        plt.plot(x, y, c=color_map.get(k), label=k, marker='o')\n",
    "        \n",
    "    recorder.close()\n",
    "\n",
    "plt.xticks(np.arange(0,1,step=0.1))\n",
    "plt.xlim(0,1)\n",
    "plt.legend(bbox_to_anchor=(1.5, 1))\n",
    "plt.tight_layout()\n",
    "plt.xlabel('predictive probability')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC over confidence\n",
    "plt.figure(figsize=(10, 3))\n",
    "bins = 15\n",
    "\n",
    "for k,v in fileConfig.items():\n",
    "    recorder = H5Recorder(v)\n",
    "    recorder.open(read=True)\n",
    "    label = recorder.read('label')\n",
    "    prob = recorder.read('prob')\n",
    "    \n",
    "    if k not in ['BEHRT']:\n",
    "        # AUROC of mean of predictive probabilities\n",
    "        prob_mean = np.mean(prob, axis=1).reshape(-1)\n",
    "        \n",
    "        x, boundry, y = roc_confidence(prob_mean, label, bins)\n",
    "        \n",
    "        idx = ~np.isnan(y)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "        idx = np.array(~(y==0))\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "        \n",
    "        plt.plot(x, y, c=color_map.get(k), label=k)\n",
    "        \n",
    "    recorder.close()\n",
    "\n",
    "plt.xticks(np.arange(0,1.1,step=0.1))\n",
    "plt.xlim(0,1)\n",
    "plt.legend(bbox_to_anchor=(1.5, 1))\n",
    "plt.tight_layout()\n",
    "plt.xlabel('predictive probability')\n",
    "plt.ylabel('auroc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "bins=50\n",
    "\n",
    "for k,v in fileConfig.items():\n",
    "    recorder = H5Recorder(v)\n",
    "    recorder.open(read=True)\n",
    "    label = recorder.read('label')\n",
    "    prob = recorder.read('prob')\n",
    "    \n",
    "    if k not in ['BEHRT']:\n",
    "        num_sample = prob.shape[1]\n",
    "        acc_list = []\n",
    "        center_list = []\n",
    "        for i in range(num_sample):\n",
    "            y_score, empirical_prob, center=reliability_curve(y_true=label, y_score=prob[:,i].reshape(-1), bins=bins)\n",
    "            acc_list.append(empirical_prob)\n",
    "            center_list.append(center)\n",
    "        \n",
    "       \n",
    "        \n",
    "        acc_list = np.stack(acc_list, axis=0)\n",
    "        center_list = np.stack(center_list, axis=0)\n",
    "\n",
    "        mean_acc = np.mean(acc_list, axis=0)\n",
    "        std_acc = np.std(acc_list, axis=0)\n",
    "        center = np.mean(center_list, axis=0)\n",
    "        \n",
    "        idx = ~np.isnan(mean_acc)\n",
    "        x = center[idx]\n",
    "        y = mean_acc[idx]\n",
    "        sigma = std_acc[idx]\n",
    "        \n",
    "        plt.plot(x, y, color_map.get(k), label=k)\n",
    "        plt.fill(np.concatenate([x, x[::-1]]), np.concatenate([y - 1.96 * sigma,(y + 1.96 * sigma)[::-1]]),\n",
    "                 alpha=.5, fc=color_map.get(k), ec='None')\n",
    "    \n",
    "    recorder.close()\n",
    "\n",
    "plt.plot(np.linspace(0,1,bins), np.linspace(0,1, bins), label='Perfect Calibrated')\n",
    "plt.xticks(np.arange(0,1.1,step=0.1))\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.legend(bbox_to_anchor=(1.5, 1))\n",
    "plt.tight_layout()\n",
    "plt.xlabel('predictive probability')\n",
    "plt.ylabel('fraction of positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty difference for samples with probability fall into specific group\n",
    "n_bins=15\n",
    "\n",
    "df_list = []\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "# for patient ever with sample probability higher than 0.9\n",
    "for k,v in fileConfig.items():\n",
    "    recorder = H5Recorder(v)\n",
    "    recorder.open(read=True)\n",
    "    label = recorder.read('label')\n",
    "    prob = recorder.read('prob')\n",
    "    \n",
    "    label = np.array(label)\n",
    "    prob = np.array(prob)\n",
    "    \n",
    "    if k not in ['BEHRT']:\n",
    "        mean_prob = np.mean(prob, axis=1).reshape(-1)\n",
    "        std_prob = np.std(prob, axis=1).reshape(-1)\n",
    "        \n",
    "        idx = (mean_prob>0)&(mean_prob<0.5)\n",
    "        \n",
    "        patient_prob = mean_prob[idx]\n",
    "        patient_std = std_prob[idx]\n",
    "        patient_label = label[idx]\n",
    "        \n",
    "        patient_pos = patient_std[patient_label==1]\n",
    "        patient_neg = patient_std[patient_label==0]\n",
    "        \n",
    "        pos_dist = torch.distributions.Normal(loc=torch.tensor(np.mean(patient_pos)), scale=torch.tensor(np.std(patient_pos)))\n",
    "        neg_dist = torch.distributions.Normal(loc=torch.tensor(np.mean(patient_neg)), scale=torch.tensor(np.std(patient_neg)))\n",
    "        kl = dist.kl_divergence(neg_dist, pos_dist)\n",
    "        print('kl divergence {}:{}'.format(k, kl))\n",
    "        \n",
    "        temp_df = pd.DataFrame({'model': k, 'label': patient_label, 'std': patient_std})\n",
    "        df_list.append(temp_df)\n",
    "    recorder.close()\n",
    "    \n",
    "df = pd.concat(df_list)\n",
    "\n",
    "sns.boxplot(x=\"model\", y='std', hue=\"label\",data=df, showfliers=False)\n",
    "plt.legend(bbox_to_anchor=(1.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Analysis\n",
    "weights = torch.load('')\n",
    "word_dict = load_obj('')['token2idx']\n",
    "word_emb_loc = weights['bert.embeddings.word_embeddings.weight_posterior.loc'].cpu()\n",
    "word_emb_scale = weights['bert.embeddings.word_embeddings.weight_posterior.scale'].cpu()\n",
    "sigma = F.softplus(word_emb_scale)\n",
    "dist = distribution.Normal(loc=word_emb_loc, scale=sigma)\n",
    "entropy = dist.entropy().sum(dim=1)\n",
    "entropy_df = pd.DataFrame({'code': list(word_dict.keys()), 'entropy':entropy.numpy()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_df.sort_values(by='entropy', ascending=True)[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_df.sort_values(by='entropy', ascending=False)[0:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
